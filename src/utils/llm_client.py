# src/utils/llm_client.py
"""
–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM –º–æ–¥–µ–ª—è–º–∏
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç qwen3-4b —á–µ—Ä–µ–∑ LM Studio (localhost:1234)
"""

import json
import asyncio
try:
    from langchain_gigachat import GigaChat
    GIGACHAT_AVAILABLE = True
except ImportError:
    GIGACHAT_AVAILABLE = False
    GigaChat = None

from .llm_config_manager import LLMProvider, LLMConfig, get_llm_config_manager
from typing import Dict, List, Optional, Any, AsyncGenerator

from dataclasses import dataclass
from datetime import datetime

import httpx
from pydantic import BaseModel, Field


class LLMMessage(BaseModel):
    """–°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è LLM"""
    role: str = Field(..., description="–†–æ–ª—å: system, user, assistant")
    content: str = Field(..., description="–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è")


class LLMResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –æ—Ç LLM"""
    content: str = Field(..., description="–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞")
    finish_reason: str = Field(..., description="–ü—Ä–∏—á–∏–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")
    usage: Dict[str, int] = Field(default_factory=dict, description="–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
    model: str = Field(..., description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
    created: datetime = Field(default_factory=datetime.now, description="–í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è")


class LLMError(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å LLM"""
    
    def __init__(self, message: str, status_code: Optional[int] = None, response_data: Optional[Dict] = None):
        super().__init__(message)
        self.status_code = status_code
        self.response_data = response_data


# –¢–û–ß–ï–ß–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ó–∞–º–µ–Ω–∏—Ç–µ –∫–ª–∞—Å—Å LLMConfig –≤ llm_client.py



class LLMClient:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM —á–µ—Ä–µ–∑ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API"""

    def __init__(self, config: Optional[LLMConfig] = None):
        if config is None:
            try:
                self.config = LLMConfig.from_manager()
            except Exception as e:
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –æ—à–∏–±–∫–∞ –≤–º–µ—Å—Ç–æ fallback –Ω–∞ LM Studio
                raise LLMError(
                    f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LLM: {str(e)}. "
                    f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è LLM_PROVIDER, GIGACHAT_CERT_PATH, GIGACHAT_KEY_PATH"
                ) from e
        else:
            self.config = config

        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã—Ö API (LM Studio, OpenAI)
        if self.config.provider != LLMProvider.GIGACHAT:
            self.client = httpx.AsyncClient(
                base_url=self.config.base_url,
                timeout=self.config.timeout
            )
        else:
            # –î–ª—è GigaChat httpx –∫–ª–∏–µ–Ω—Ç –Ω–µ –Ω—É–∂–µ–Ω
            self.client = None

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_requests = 0
        self.total_tokens = 0
        self.error_count = 0

    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.close()
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –∫–ª–∏–µ–Ω—Ç–∞"""
        await self.client.aclose()
    
    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ LLM —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            response = await self.client.get("/v1/models", timeout=10)
            return response.status_code == 200
        except Exception:
            return False
    
    async def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            response = await self.client.get("/v1/models")
            response.raise_for_status()
            
            data = response.json()
            return [model["id"] for model in data.get("data", [])]
        except Exception as e:
            raise LLMError(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {str(e)}")
    
    async def complete_chat(
        self,
        messages: List[LLMMessage],
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        stream: bool = False
    ) -> LLMResponse:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ chat completion –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –º–æ–¥–µ–ª–∏
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ config)
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            stream: –ü–æ—Ç–æ–∫–æ–≤—ã–π —Ä–µ–∂–∏–º
        """
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        request_data = {
            "model": model or self.config.model,
            "messages": [msg.dict() for msg in messages],
            "temperature": temperature or self.config.temperature,
            "max_tokens": max_tokens or self.config.max_tokens,
            "stream": stream
        }
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏
        for attempt in range(self.config.max_retries):
            try:
                response = await self.client.post(
                    "/v1/chat/completions",
                    json=request_data,
                    timeout=self.config.timeout
                )
                response.raise_for_status()
                
                data = response.json()
                
                # –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
                choice = data["choices"][0]
                usage = data.get("usage", {})
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                self.total_requests += 1
                self.total_tokens += usage.get("total_tokens", 0)
                
                return LLMResponse(
                    content=choice["message"]["content"],
                    finish_reason=choice["finish_reason"],
                    usage=usage,
                    model=data["model"],
                    created=datetime.now()
                )
                
            except httpx.HTTPStatusError as e:
                self.error_count += 1
                error_msg = f"HTTP {e.response.status_code}: {e.response.text}"
                
                if attempt == self.config.max_retries - 1:
                    raise LLMError(
                        f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM –ø–æ—Å–ª–µ {self.config.max_retries} –ø–æ–ø—ã—Ç–æ–∫: {error_msg}",
                        status_code=e.response.status_code,
                        response_data=e.response.json() if e.response.text else None
                    )
                
                # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
                await asyncio.sleep(self.config.retry_delay * (attempt + 1))
                
            except Exception as e:
                self.error_count += 1
                if attempt == self.config.max_retries - 1:
                    raise LLMError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
                
                await asyncio.sleep(self.config.retry_delay * (attempt + 1))
    
    async def complete_chat_stream(
        self,
        messages: List[LLMMessage],
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> AsyncGenerator[str, None]:
        """
        –ü–æ—Ç–æ–∫–æ–≤—ã–π chat completion
        
        Yields:
            –§—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç–∞
        """
        
        request_data = {
            "model": model or self.config.model,
            "messages": [msg.dict() for msg in messages],
            "temperature": temperature or self.config.temperature,
            "max_tokens": max_tokens or self.config.max_tokens,
            "stream": True
        }
        
        try:
            async with self.client.stream(
                "POST", 
                "/v1/chat/completions",
                json=request_data
            ) as response:
                response.raise_for_status()
                
                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        data_str = line[6:]  # –£–±–∏—Ä–∞–µ–º "data: "
                        
                        if data_str == "[DONE]":
                            break
                        
                        try:
                            data = json.loads(data_str)
                            choice = data["choices"][0]
                            
                            if "delta" in choice and "content" in choice["delta"]:
                                content = choice["delta"]["content"]
                                if content:
                                    yield content
                                    
                        except json.JSONDecodeError:
                            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ JSON —Å—Ç—Ä–æ–∫–∏
                            continue
                            
        except Exception as e:
            raise LLMError(f"–û—à–∏–±–∫–∞ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
    
    async def analyze_with_prompt(
        self,
        system_prompt: str,
        user_input: str,
        context: Optional[str] = None,
        model: Optional[str] = None,
        temperature: Optional[float] = None
    ) -> LLMResponse:
        """
        –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å –ø—Ä–æ–º–ø—Ç–æ–º
        
        Args:
            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏
            user_input: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        
        messages = [
            LLMMessage(role="system", content=system_prompt)
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
        if context:
            messages.append(
                LLMMessage(
                    role="user", 
                    content=f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–ó–∞–¥–∞—á–∞:\n{user_input}"
                )
            )
        else:
            messages.append(LLMMessage(role="user", content=user_input))
        
        return await self.complete_chat(
            messages=messages,
            model=model,
            temperature=temperature
        )
    
    async def extract_structured_data(
        self,
        data_to_analyze: str,
        extraction_prompt: str,
        expected_format: str = "JSON",
        model: Optional[str] = None
    ) -> Dict[str, Any]:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ù–ê–î–ï–ñ–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        
        system_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö. 

        –¢–≤–æ—è –∑–∞–¥–∞—á–∞: {extraction_prompt}

        –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
        - –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º {expected_format} –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        - –ù–ï –¥–æ–±–∞–≤–ª—è–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –ø–æ—è—Å–Ω–µ–Ω–∏—è, —Ç–µ–≥–∏ <think> –∏–ª–∏ markdown –±–ª–æ–∫–∏
        - –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–π —Ä–∞–∑—É–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        - –°—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–∞–Ω–Ω—ã—Ö
        - –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–∞–º–∏, –Ω–µ —Å—Ç—Ä–æ–∫–∞–º–∏
        - –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–æ–ª–∂–Ω—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
        - –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –∑–∞–ø—è—Ç—ã–µ –≤ –∫–æ–Ω—Ü–µ –æ–±—ä–µ–∫—Ç–æ–≤ –∏–ª–∏ –º–∞—Å—Å–∏–≤–æ–≤

        –ü–†–ò–ú–ï–† –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –§–û–†–ú–ê–¢–ê:
        {{
            "probability_score": 3,
            "impact_score": 4,
            "total_score": 12,
            "risk_level": "medium",
            "probability_reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏",
            "impact_reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è",
            "key_factors": ["—Ñ–∞–∫—Ç–æ—Ä1", "—Ñ–∞–∫—Ç–æ—Ä2"],
            "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è1", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è2"],
            "confidence_level": 0.8
        }}

        –°–¢–†–û–ì–û: –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON, –Ω–∞—á–∏–Ω–∞—é—â–∏–π—Å—è —Å {{ –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∏–π—Å—è }}"""

        max_retries = 4  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        last_error = None
        
        for attempt in range(max_retries):
            try:
                response = await self.analyze_with_prompt(
                    system_prompt=system_prompt,
                    user_input=f"–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:\n{data_to_analyze}",
                    model=model,
                    temperature=0.05 if attempt == 0 else 0.1  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –ø–µ—Ä–≤–æ–π –ø–æ–ø—ã—Ç–∫–∏
                )
                
                # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –£–õ–£–ß–®–ï–ù–ù–ê–Ø –æ—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
                parsed_result = self._ultra_robust_json_parser(response.content)
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∞–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                validated_result = self._validate_and_fix_json_structure(parsed_result)
                
                return validated_result
                
            except Exception as e:
                last_error = e
                
                if attempt < max_retries - 1:
                    # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–∏
                    system_prompt += f"\n\n–í–ù–ò–ú–ê–ù–ò–ï: –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –∏–∑ {max_retries}. –ü—Ä–µ–¥—ã–¥—É—â–∞—è –æ—à–∏–±–∫–∞: {str(e)[:100]}. –ë—É–¥—å –û–°–û–ë–ï–ù–ù–û –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã–º –∫ —Ñ–æ—Ä–º–∞—Ç—É JSON!"
                    
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
                    await asyncio.sleep(1 + attempt)
                else:
                    # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º fallback
                    return self._create_emergency_fallback_result(extraction_prompt, str(e))
        
        # –ù–µ –¥–æ–ª–∂–Ω–æ –¥–æ—Å—Ç–∏–≥–∞—Ç—å—Å—è, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        return self._create_emergency_fallback_result(extraction_prompt, str(last_error))
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return {
            "total_requests": self.total_requests,
            "total_tokens": self.total_tokens,
            "error_count": self.error_count,
            "success_rate": (self.total_requests - self.error_count) / max(self.total_requests, 1),
            "avg_tokens_per_request": self.total_tokens / max(self.total_requests, 1)
        }
    def _ultra_robust_json_parser(self, content: str) -> Dict[str, Any]:
        """–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –Ω–∞–¥–µ–∂–Ω—ã–π –ø–∞—Ä—Å–µ—Ä JSON —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏"""
        
        import re
        import json
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
        cleaned = content.strip()
        
        # –£–¥–∞–ª—è–µ–º —Ç–µ–≥–∏ <think>...</think>
        cleaned = re.sub(r'<think>.*?</think>', '', cleaned, flags=re.DOTALL).strip()
        
        # –£–¥–∞–ª—è–µ–º markdown –±–ª–æ–∫–∏
        if '```json' in cleaned:
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ JSON –±–ª–æ–∫–∏
            json_blocks = re.findall(r'```json\s*(.*?)\s*```', cleaned, re.DOTALL)
            if json_blocks:
                cleaned = json_blocks[-1].strip()
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–≥–æ —Ç–µ–≥–∞
                start = cleaned.find('```json') + 7
                cleaned = cleaned[start:].strip()
        
        # –£–¥–∞–ª—è–µ–º –æ–±—ã—á–Ω—ã–µ markdown –±–ª–æ–∫–∏
        cleaned = re.sub(r'```.*?```', '', cleaned, flags=re.DOTALL).strip()
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü–æ–∏—Å–∫ JSON –æ–±—ä–µ–∫—Ç–∞
        strategies = [
            # 1. –ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥
            lambda x: json.loads(x),
            
            # 2. –ü–æ–∏—Å–∫ –ø–æ —Ñ–∏–≥—É—Ä–Ω—ã–º —Å–∫–æ–±–∫–∞–º
            lambda x: json.loads(self._extract_json_by_braces(x)),
            
            # 3. –ü–æ–∏—Å–∫ –ø–æ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–º—É –≤—ã—Ä–∞–∂–µ–Ω–∏—é
            lambda x: json.loads(self._extract_json_by_regex(x)),
            
            # 4. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏ –ø–∞—Ä—Å–∏–Ω–≥
            lambda x: json.loads(self._fix_common_json_issues(x)),
            
            # 5. –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            lambda x: json.loads(self._aggressive_json_fix(x))
        ]
        
        for i, strategy in enumerate(strategies):
            try:
                result = strategy(cleaned)
                if isinstance(result, dict):
                    return result
            except Exception as e:
                if i == len(strategies) - 1:
                    # –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞
                    raise Exception(f"–í—Å–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {e}")
                continue
        
        raise Exception("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π")
    def _extract_json_by_braces(self, content: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –ø–æ —Ñ–∏–≥—É—Ä–Ω—ã–º —Å–∫–æ–±–∫–∞–º"""
        
        # –ò—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É
        start = content.find('{')
        if start == -1:
            raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –æ—Ç–∫—Ä—ã–≤–∞—é—â–∞—è —Ñ–∏–≥—É—Ä–Ω–∞—è —Å–∫–æ–±–∫–∞")
        
        # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∑–∞–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É
        brace_count = 0
        end = start
        
        for i, char in enumerate(content[start:], start):
            if char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    end = i
                    break
        
        if brace_count != 0:
            # –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∑–∞–∫—Ä—ã–≤–∞—é—â–∞—è —Å–∫–æ–±–∫–∞, –±–µ—Ä–µ–º –¥–æ –∫–æ–Ω—Ü–∞
            end = len(content) - 1
        
        return content[start:end + 1]

    def _extract_json_by_regex(self, content: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è"""
        
        import re
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ JSON –æ–±—ä–µ–∫—Ç–∞
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        
        matches = re.findall(json_pattern, content, re.DOTALL)
        if matches:
            # –ë–µ—Ä–µ–º —Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π JSON
            return max(matches, key=len)
        
        raise ValueError("JSON –æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º")

    def _fix_common_json_issues(self, content: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ JSON"""
        
        import re
        
        # 1. –£–±–∏—Ä–∞–µ–º trailing commas
        content = re.sub(r',\s*}', '}', content)
        content = re.sub(r',\s*]', ']', content)
        
        # 2. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –Ω–∞ –¥–≤–æ–π–Ω—ã–µ
        content = re.sub(r"'([^']*)':", r'"\1":', content)  # –ö–ª—é—á–∏
        content = re.sub(r":\s*'([^']*)'", r': "\1"', content)  # –ó–Ω–∞—á–µ–Ω–∏—è
        
        # 3. –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏ –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º –±–µ–∑ –∫–∞–≤—ã—á–µ–∫ (–∫—Ä–æ–º–µ —á–∏—Å–µ–ª, bool, null)
        content = re.sub(r':\s*([^",{\[\]\s][^,}\]]*[^",}\]\s])\s*[,}]', 
                        lambda m: f': "{m.group(1).strip()}"' + m.group(0)[-1], content)
        
        # 4. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫
        content = re.sub(r'(?<!\\)"(?=[^,}\]]*[,}\]])', '\\"', content)
        
        # 5. –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        content = re.sub(r'//.*?\n', '\n', content)
        content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
        
        # 6. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        content = re.sub(r'\s+', ' ', content)
        
        return content.strip()

    def _aggressive_json_fix(self, content: str) -> str:
        """–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ JSON - –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞"""
        
        import re
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –±–∞–∑–æ–≤–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        content = self._fix_common_json_issues(content)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å {, –¥–æ–±–∞–≤–ª—è–µ–º
        if not content.strip().startswith('{'):
            content = '{' + content
        
        # –ï—Å–ª–∏ –Ω–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ }, –¥–æ–±–∞–≤–ª—è–µ–º
        if not content.strip().endswith('}'):
            content = content + '}'
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ –∫–∞–≤—ã—á–∫–∏
        lines = content.split('\n')
        fixed_lines = []
        
        for line in lines:
            # –°—á–∏—Ç–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –≤ —Å—Ç—Ä–æ–∫–µ
            quote_count = line.count('"') - line.count('\\"')
            
            # –ï—Å–ª–∏ –Ω–µ—á–µ—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–≤—ã—á–µ–∫, –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â—É—é
            if quote_count % 2 == 1:
                if ':' in line and not line.strip().endswith('"'):
                    line = line.rstrip() + '"'
            
            fixed_lines.append(line)
        
        content = '\n'.join(fixed_lines)
        
        # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - —É–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–æ –ø–µ—Ä–≤–æ–π { –∏ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π }
        start = content.find('{')
        end = content.rfind('}')
        
        if start != -1 and end != -1 and end > start:
            content = content[start:end + 1]
        
        return content

    def _validate_and_fix_json_structure(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        if self._looks_like_risk_evaluation(data):
            return self._fix_risk_evaluation_structure(data)
        elif self._looks_like_critic_evaluation(data):
            return self._fix_critic_evaluation_structure(data)
        else:
            # –û–±—â–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
            return self._fix_general_structure(data)

    def _looks_like_risk_evaluation(self, data: Dict[str, Any]) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ—Ü–µ–Ω–∫–æ–π —Ä–∏—Å–∫–∞"""
        
        risk_fields = {"probability_score", "impact_score", "total_score", "risk_level"}
        return any(field in data for field in risk_fields)

    def _looks_like_critic_evaluation(self, data: Dict[str, Any]) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–æ–π"""
        
        critic_fields = {"quality_score", "is_acceptable", "critic_reasoning"}
        return any(field in data for field in critic_fields)

    def _fix_risk_evaluation_structure(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞"""
        
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        required_fields = {
            "probability_score": 3,
            "impact_score": 3,
            "total_score": 9,
            "risk_level": "medium",
            "probability_reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ",
            "impact_reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ",
            "key_factors": [],
            "recommendations": [],
            "confidence_level": 0.7
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è
        for field, default_value in required_fields.items():
            if field not in data or data[field] is None:
                data[field] = default_value
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–∏–ø—ã –∏ –¥–∏–∞–ø–∞–∑–æ–Ω—ã
        data["probability_score"] = self._ensure_int_range(data["probability_score"], 1, 5, 3)
        data["impact_score"] = self._ensure_int_range(data["impact_score"], 1, 5, 3)
        data["confidence_level"] = self._ensure_float_range(data["confidence_level"], 0.0, 1.0, 0.7)
        
        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º total_score
        data["total_score"] = data["probability_score"] * data["impact_score"]
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º risk_level
        total_score = data["total_score"]
        if total_score <= 6:
            data["risk_level"] = "low"
        elif total_score <= 14:
            data["risk_level"] = "medium"
        else:
            data["risk_level"] = "high"
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏
        data["key_factors"] = self._ensure_string_list(data["key_factors"])
        data["recommendations"] = self._ensure_string_list(data["recommendations"])
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏
        data["probability_reasoning"] = self._ensure_string(data["probability_reasoning"], "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ")
        data["impact_reasoning"] = self._ensure_string(data["impact_reasoning"], "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ")
        
        return data

    def _fix_critic_evaluation_structure(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏"""
        
        required_fields = {
            "quality_score": 5.0,
            "is_acceptable": True,
            "issues_found": [],
            "improvement_suggestions": [],
            "critic_reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ"
        }
        
        for field, default_value in required_fields.items():
            if field not in data or data[field] is None:
                data[field] = default_value
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        data["quality_score"] = self._ensure_float_range(data["quality_score"], 0.0, 10.0, 5.0)
        data["is_acceptable"] = bool(data.get("is_acceptable", True))
        data["issues_found"] = self._ensure_string_list(data["issues_found"])
        data["improvement_suggestions"] = self._ensure_string_list(data["improvement_suggestions"])
        data["critic_reasoning"] = self._ensure_string(data["critic_reasoning"], "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ")
        
        return data

    def _fix_general_structure(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±—â–µ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        
        # –ü—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ, —É–±–µ–¥–∏–≤—à–∏—Å—å —á—Ç–æ —ç—Ç–æ dict
        if not isinstance(data, dict):
            return {"error": "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö", "original_data": str(data)}
        
        return data

    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏

    def _ensure_int_range(self, value: Any, min_val: int, max_val: int, default: int) -> int:
        """–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ"""
        try:
            int_val = int(float(value))  # –°–Ω–∞—á–∞–ª–∞ float, –ø–æ—Ç–æ–º int –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ "3.0"
            return max(min_val, min(max_val, int_val))
        except (ValueError, TypeError):
            return default

    def _ensure_float_range(self, value: Any, min_val: float, max_val: float, default: float) -> float:
        """–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —á–∏—Å–ª–æ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ"""
        try:
            float_val = float(value)
            return max(min_val, min(max_val, float_val))
        except (ValueError, TypeError):
            return default

    def _ensure_string(self, value: Any, default: str) -> str:
        """–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"""
        if not value or not isinstance(value, str) or len(value.strip()) < 3:
            return default
        return str(value).strip()

    def _ensure_string_list(self, value: Any) -> List[str]:
        """–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫"""
        if not isinstance(value, list):
            return []
        
        result = []
        for item in value:
            if item and isinstance(item, str) and len(item.strip()) > 0:
                result.append(str(item).strip())
        
        return result[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤

    def _create_emergency_fallback_result(self, extraction_prompt: str, error_message: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –∞–≤–∞—Ä–∏–π–Ω—ã–π fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–≥–¥–∞ –≤—Å–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å"""
        
        # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –ø–æ –ø—Ä–æ–º–ø—Ç—É
        prompt_lower = extraction_prompt.lower()
        
        if any(keyword in prompt_lower for keyword in ['—Ä–∏—Å–∫', 'risk', '–æ—Ü–µ–Ω', 'evaluat']):
            # –≠—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–∞
            return {
                "probability_score": 3,
                "impact_score": 3,
                "total_score": 9,
                "risk_level": "medium",
                "probability_reasoning": f"–ê–≤–∞—Ä–∏–π–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: LLM –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON. –û—à–∏–±–∫–∞: {error_message}",
                "impact_reasoning": f"–ê–≤–∞—Ä–∏–π–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: LLM –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON. –û—à–∏–±–∫–∞: {error_message}",
                "key_factors": ["–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ LLM"],
                "recommendations": ["–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º–ø—Ç–∞", "–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –æ—Ü–µ–Ω–∫—É", "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM"],
                "confidence_level": 0.1
            }
        
        elif any(keyword in prompt_lower for keyword in ['–∫—Ä–∏—Ç–∏–∫', 'critic', '–∫–∞—á–µ—Å—Ç–≤', 'quality']):
            # –≠—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫—É—é –æ—Ü–µ–Ω–∫—É
            return {
                "quality_score": 3.0,
                "is_acceptable": False,
                "issues_found": ["LLM –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON", f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {error_message}"],
                "improvement_suggestions": ["–£–ª—É—á—à–∏—Ç—å –ø—Ä–æ–º–ø—Ç", "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM", "–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –æ—Ü–µ–Ω–∫—É"],
                "critic_reasoning": f"–ê–≤–∞—Ä–∏–π–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç LLM. –û—à–∏–±–∫–∞: {error_message}"
            }
        
        else:
            # –û–±—â–∏–π fallback
            return {
                "error": "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ LLM –æ—Ç–≤–µ—Ç–∞",
                "error_message": error_message,
                "extraction_prompt": extraction_prompt,
                "fallback_response": True
            }

# ===============================
# –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤
# ===============================

class RiskAnalysisLLMClient(LLMClient):
    """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤"""
    
    def __init__(self, config: Optional[LLMConfig] = None):
        super().__init__(config)
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤
        if self.config.temperature > 0.3:
            self.config.temperature = 0.2  # –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
    
    async def evaluate_risk(
        self,
        risk_type: str,
        agent_data: str,
        evaluation_criteria: str,
        examples: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        
        Args:
            risk_type: –¢–∏–ø —Ä–∏—Å–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
            agent_data: –î–∞–Ω–Ω—ã–µ –æ–± –∞–≥–µ–Ω—Ç–µ
            evaluation_criteria: –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏
            examples: –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        """
        
        system_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ü–µ–Ω–∫–µ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –≤ –±–∞–Ω–∫–æ–≤—Å–∫–æ–π —Å—Ñ–µ—Ä–µ.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –æ—Ü–µ–Ω–∏—Ç—å {risk_type} –¥–ª—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –ò–ò-–∞–≥–µ–Ω—Ç–∞.

–ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:
{evaluation_criteria}

–®–ö–ê–õ–ê –û–¶–ï–ù–ö–ò:
- –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: 1-5 –±–∞–ª–ª–æ–≤ (1=–Ω–∏–∑–∫–∞—è, 5=–≤—ã—Å–æ–∫–∞—è)
- –¢—è–∂–µ—Å—Ç—å: 1-5 –±–∞–ª–ª–æ–≤ (1=–Ω–∏–∑–∫–∏–µ –ø–æ—Ç–µ—Ä–∏, 5=–≤—ã—Å–æ–∫–∏–µ –ø–æ—Ç–µ—Ä–∏)
- –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª = –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å √ó –¢—è–∂–µ—Å—Ç—å

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–°–¢–†–û–ì–û JSON):
{{
    "probability_score": <1-5>,
    "impact_score": <1-5>,
    "total_score": <1-25>,
    "risk_level": "<low|medium|high>",
    "probability_reasoning": "<–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏>",
    "impact_reasoning": "<–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ —Ç—è–∂–µ—Å—Ç–∏>",
    "key_factors": ["<—Ñ–∞–∫—Ç–æ—Ä1>", "<—Ñ–∞–∫—Ç–æ—Ä2>", ...],
    "recommendations": ["<—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è1>", "<—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è2>", ...],
    "confidence_level": <0.0-1.0>
}}

–£–†–û–í–ù–ò –†–ò–°–ö–ê:
- low: 1-6 –±–∞–ª–ª–æ–≤
- medium: 7-14 –±–∞–ª–ª–æ–≤  
- high: 15-25 –±–∞–ª–ª–æ–≤"""

        if examples:
            system_prompt += f"\n\n–ü–†–ò–ú–ï–†–´ –û–¶–ï–ù–û–ö:\n{examples}"

        response = await self.extract_structured_data(
            data_to_analyze=agent_data,
            extraction_prompt=f"–û—Ü–µ–Ω–∏ {risk_type} —Å–æ–≥–ª–∞—Å–Ω–æ –º–µ—Ç–æ–¥–∏–∫–µ",
            expected_format="JSON"
        )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        required_fields = [
            "probability_score", "impact_score", "total_score", 
            "risk_level", "probability_reasoning", "impact_reasoning"
        ]
        
        for field in required_fields:
            if field not in response:
                raise LLMError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ –≤ –æ—Ç–≤–µ—Ç–µ: {field}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π
        if not (1 <= response["probability_score"] <= 5):
            raise LLMError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π probability_score: {response['probability_score']}")
        
        if not (1 <= response["impact_score"] <= 5):
            raise LLMError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π impact_score: {response['impact_score']}")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ—Å—á–µ—Ç total_score –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        response["total_score"] = response["probability_score"] * response["impact_score"]
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ risk_level
        score = response["total_score"]
        if score <= 6:
            response["risk_level"] = "low"
        elif score <= 14:
            response["risk_level"] = "medium"
        else:
            response["risk_level"] = "high"
        
        return response
    
    async def critique_evaluation(
        self,
        risk_type: str,
        original_evaluation: Dict[str, Any],
        agent_data: str,
        quality_threshold: float = 7.0
    ) -> Dict[str, Any]:
        """
        –ö—Ä–∏—Ç–∏–∫–∞ –æ—Ü–µ–Ω–∫–∏ –¥—Ä—É–≥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        
        Args:
            risk_type: –¢–∏–ø —Ä–∏—Å–∫–∞
            original_evaluation: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏
            agent_data: –î–∞–Ω–Ω—ã–µ –æ–± –∞–≥–µ–Ω—Ç–µ
            quality_threshold: –ü–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ (0-10)
        """
        
        system_prompt = f"""–¢—ã - –∫—Ä–∏—Ç–∏–∫-—ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ü–µ–Ω–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ {risk_type}.

–ö–†–ò–¢–ï–†–ò–ò –ö–ê–ß–ï–°–¢–í–ê:
1. –û–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–æ–∫ (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–∞–Ω–Ω—ã–º –∞–≥–µ–Ω—Ç–∞)
2. –ü–æ–ª–Ω–æ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ (—É—á—Ç–µ–Ω—ã –ª–∏ –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã)
3. –õ–æ–≥–∏—á–Ω–æ—Å—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
4. –ü—Ä–∞–∫—Ç–∏—á–Ω–æ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
5. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ—Ç–æ–¥–∏–∫–µ –æ—Ü–µ–Ω–∫–∏

–®–ö–ê–õ–ê –ö–ê–ß–ï–°–¢–í–ê: 0-10 –±–∞–ª–ª–æ–≤
–ü–û–†–û–ì –ü–†–ò–ï–ú–õ–ï–ú–û–°–¢–ò: {quality_threshold} –±–∞–ª–ª–æ–≤

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–°–¢–†–û–ì–û JSON):
{{
    "quality_score": <0.0-10.0>,
    "is_acceptable": <true|false>,
    "issues_found": ["<–ø—Ä–æ–±–ª–µ–º–∞1>", "<–ø—Ä–æ–±–ª–µ–º–∞2>", ...],
    "improvement_suggestions": ["<–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ1>", "<–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ2>", ...],
    "critic_reasoning": "<–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞>"
}}"""

        evaluation_text = json.dumps(original_evaluation, ensure_ascii=False, indent=2)
        
        context = f"""–î–ê–ù–ù–´–ï –û–ë –ê–ì–ï–ù–¢–ï:
{agent_data}

–û–¶–ï–ù–ö–ê –î–õ–Ø –ö–†–ò–¢–ò–ö–ò:
{evaluation_text}"""

        response = await self.extract_structured_data(
            data_to_analyze=context,
            extraction_prompt="–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞",
            expected_format="JSON"
        )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        required_fields = ["quality_score", "is_acceptable", "critic_reasoning"]
        for field in required_fields:
            if field not in response:
                raise LLMError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {field}")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–µ–º–ª–µ–º–æ—Å—Ç–∏
        response["is_acceptable"] = response["quality_score"] >= quality_threshold
        
        return response

class GigaChatLLMClient(LLMClient):
    """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GigaChat —á–µ—Ä–µ–∑ langchain_gigachat"""
    
    def __init__(self, config: Optional[LLMConfig] = None):
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
        self.config = config or LLMConfig.from_manager()
        
        if not GIGACHAT_AVAILABLE:
            raise ImportError(
                "langchain_gigachat –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install langchain-gigachat"
            )
        
        if self.config.provider != LLMProvider.GIGACHAT:
            raise ValueError("GigaChatLLMClient —Ç—Ä–µ–±—É–µ—Ç provider=GIGACHAT")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤
        if not (self.config.cert_file and self.config.key_file):
            raise ValueError("–î–ª—è GigaChat –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã cert_file –∏ key_file")
        
        # –°–æ–∑–¥–∞–µ–º GigaChat –∫–ª–∏–µ–Ω—Ç
        self.gigachat = GigaChat(
            base_url=self.config.base_url,
            cert_file=self.config.cert_file,
            key_file=self.config.key_file,
            model=self.config.model,
            temperature=self.config.temperature,
            top_p=self.config.top_p,
            verify_ssl_certs=self.config.verify_ssl_certs,
            profanity_check=self.config.profanity_check,
            streaming=self.config.streaming
        )
        
        # –í–ê–ñ–ù–û: –ù–ï —Å–æ–∑–¥–∞–µ–º httpx –∫–ª–∏–µ–Ω—Ç –¥–ª—è GigaChat
        self.client = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_requests = 0
        self.total_tokens = 0
        self.error_count = 0
    
    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GigaChat"""
        try:
            print("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ GigaChat...")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: GigaChat.invoke() - —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥, –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ run_in_executor
            import asyncio
            loop = asyncio.get_event_loop()
            
            def sync_test():
                try:
                    response = self.gigachat.invoke("–ü—Ä–∏–≤–µ—Ç")
                    return response
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ GigaChat: {e}")
                    raise e
            
            response = await loop.run_in_executor(None, sync_test)
            
            print(f"ü§ñ –û—Ç–≤–µ—Ç –æ—Ç GigaChat: {type(response)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
            if hasattr(response, 'content'):
                content = response.content
                print(f"üìù –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Ç–≤–µ—Ç–∞: '{content[:50]}{'...' if len(content) > 50 else ''}'")
                is_valid = bool(content and len(content.strip()) > 0)
                print(f"‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏: {is_valid}")
                return is_valid
            else:
                print(f"‚ö†Ô∏è –û—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∞—Ç—Ä–∏–±—É—Ç 'content': {response}")
                # Fallback: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ response —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                return response is not None
                
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ health_check: {e}")
            print(f"‚ùå –¢–∏–ø –∏—Å–∫–ª—é—á–µ–Ω–∏—è: {type(e)}")
            return False
    
    async def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è GigaChat"""
        # GigaChat –æ–±—ã—á–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –º–æ–¥–µ–ª–µ–π
        return ["GigaChat", "GigaChat-Pro", "GigaChat-Max"]
    
    async def complete_chat(
        self,
        messages: List[LLMMessage],
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        stream: bool = False
    ) -> LLMResponse:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ chat completion —á–µ—Ä–µ–∑ GigaChat"""
        
        try:
            self.total_requests += 1
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –µ–¥–∏–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è GigaChat
            prompt = self._format_messages_for_gigachat(messages)
            
            # –í—Ä–µ–º–µ–Ω–Ω–æ –∏–∑–º–µ–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            original_temp = self.gigachat.temperature
            original_model = self.gigachat.model
            
            if temperature is not None:
                self.gigachat.temperature = temperature
            if model is not None:
                self.gigachat.model = model
            
            try:
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –í—ã–ø–æ–ª–Ω—è–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –≤ executor
                import asyncio
                loop = asyncio.get_event_loop()
                
                def sync_invoke():
                    return self.gigachat.invoke(prompt)
                
                response = await loop.run_in_executor(None, sync_invoke)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
                if hasattr(response, 'content'):
                    content = response.content
                else:
                    content = str(response)
                
                # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ (—Ç–∞–∫ –∫–∞–∫ GigaChat –º–æ–∂–µ—Ç –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ç–æ—á–Ω–æ–µ —á–∏—Å–ª–æ)
                estimated_tokens = len(prompt.split()) + len(content.split())
                self.total_tokens += estimated_tokens
                
                return LLMResponse(
                    content=content,
                    finish_reason="stop",
                    usage={"total_tokens": estimated_tokens, "estimated": True},
                    model=model or self.config.model,
                    created=datetime.now()
                )
                
            finally:
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                self.gigachat.temperature = original_temp
                self.gigachat.model = original_model
                
        except Exception as e:
            self.error_count += 1
            raise LLMError(f"–û—à–∏–±–∫–∞ GigaChat: {str(e)}")
    
    def _format_messages_for_gigachat(self, messages: List[LLMMessage]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –µ–¥–∏–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è GigaChat"""
        formatted_parts = []
        
        for message in messages:
            role = message.role
            content = message.content
            
            if role == "system":
                formatted_parts.append(f"–°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {content}")
            elif role == "user":
                formatted_parts.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {content}")
            elif role == "assistant":
                formatted_parts.append(f"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {content}")
            else:
                formatted_parts.append(content)
        
        return "\n\n".join(formatted_parts)
    
    async def simple_completion(self, prompt: str, **kwargs) -> str:
        """–ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –ø—Ä–æ–º–ø—Ç"""
        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º executor –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞
            import asyncio
            loop = asyncio.get_event_loop()
            
            def sync_invoke():
                return self.gigachat.invoke(prompt)
            
            response = await loop.run_in_executor(None, sync_invoke)
            return response.content if hasattr(response, 'content') else str(response)
        except Exception as e:
            raise LLMError(f"–û—à–∏–±–∫–∞ GigaChat –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
    
    async def extract_structured_data(
        self,
        data_to_analyze: str,
        extraction_prompt: str,
        expected_format: str = "JSON",
        max_attempts: int = 3
    ) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ GigaChat"""
        
        system_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö. 

        –¢–≤–æ—è –∑–∞–¥–∞—á–∞: {extraction_prompt}

        –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
        - –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º {expected_format} –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        - –ù–ï –¥–æ–±–∞–≤–ª—è–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –ø–æ—è—Å–Ω–µ–Ω–∏—è, —Ç–µ–≥–∏ <think> –∏–ª–∏ markdown –±–ª–æ–∫–∏
        - –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–π —Ä–∞–∑—É–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        - –°—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–∞–Ω–Ω—ã—Ö
        - –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–∞–º–∏, –Ω–µ —Å—Ç—Ä–æ–∫–∞–º–∏
        - –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–æ–ª–∂–Ω—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
        - –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –∑–∞–ø—è—Ç—ã–µ –≤ –∫–æ–Ω—Ü–µ –æ–±—ä–µ–∫—Ç–æ–≤ –∏–ª–∏ –º–∞—Å—Å–∏–≤–æ–≤

        –°–¢–†–û–ì–û: –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON, –Ω–∞—á–∏–Ω–∞—é—â–∏–π—Å—è —Å {{ –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∏–π—Å—è }}"""

        last_error = None
        
        for attempt in range(max_attempts):
            try:
                messages = [LLMMessage(role="user", content=f"{system_prompt}\n\n–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:\n{data_to_analyze}")]
                response = await self.complete_chat(messages, temperature=0.05 if attempt == 0 else 0.1)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –ø–∞—Ä—Å–µ—Ä —á—Ç–æ –∏ –≤ –±–∞–∑–æ–≤–æ–º –∫–ª–∞—Å—Å–µ
                parsed_result = self._ultra_robust_json_parser(response.content)
                validated_result = self._validate_and_fix_json_structure(parsed_result)
                
                return validated_result
                
            except Exception as e:
                last_error = e
                
                if attempt < max_attempts - 1:
                    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
                    await asyncio.sleep(1 + attempt)
                else:
                    # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º fallback
                    return self._create_emergency_fallback_result(extraction_prompt, str(e))
        
        return self._create_emergency_fallback_result(extraction_prompt, str(last_error))
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ GigaChat"""
        # GigaChat –∫–ª–∏–µ–Ω—Ç –∏–∑ langchain –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —è–≤–Ω–æ–≥–æ –∑–∞–∫—Ä—ã—Ç–∏—è
        pass

class GigaChatRiskAnalysisLLMClient(RiskAnalysisLLMClient):
    """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π GigaChat –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤"""
    
    def __init__(self, config: Optional[LLMConfig] = None):
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è GigaChat
        self.config = config or LLMConfig.from_manager()
        
        if not GIGACHAT_AVAILABLE:
            raise ImportError(
                "langchain_gigachat –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install langchain-gigachat"
            )
        
        if self.config.provider != LLMProvider.GIGACHAT:
            raise ValueError("GigaChatRiskAnalysisLLMClient —Ç—Ä–µ–±—É–µ—Ç provider=GIGACHAT")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤
        if not (self.config.cert_file and self.config.key_file):
            raise ValueError("–î–ª—è GigaChat –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã cert_file –∏ key_file")
        
        # –°–æ–∑–¥–∞–µ–º GigaChat –∫–ª–∏–µ–Ω—Ç
        self.gigachat = GigaChat(
            base_url=self.config.base_url,
            cert_file=self.config.cert_file,
            key_file=self.config.key_file,
            model=self.config.model,
            temperature=self.config.temperature,
            top_p=self.config.top_p,
            verify_ssl_certs=self.config.verify_ssl_certs,
            profanity_check=self.config.profanity_check,
            streaming=self.config.streaming
        )
        
        # –í–ê–ñ–ù–û: –ù–ï —Å–æ–∑–¥–∞–µ–º httpx –∫–ª–∏–µ–Ω—Ç –¥–ª—è GigaChat
        self.client = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_requests = 0
        self.total_tokens = 0
        self.error_count = 0
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤
        if self.config.temperature > 0.3:
            self.config.temperature = 0.2
    
    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GigaChat"""
        try:
            import asyncio
            loop = asyncio.get_event_loop()
            
            def sync_test():
                return self.gigachat.invoke("–ü—Ä–∏–≤–µ—Ç")
            
            response = await loop.run_in_executor(None, sync_test)
            return bool(hasattr(response, 'content') and response.content)
        except Exception:
            return False
    
    async def get_available_models(self) -> List[str]:
        return ["GigaChat", "GigaChat-Pro", "GigaChat-Max"]
    
    async def complete_chat(
        self,
        messages: List[LLMMessage],
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        stream: bool = False
    ) -> LLMResponse:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ chat completion —á–µ—Ä–µ–∑ GigaChat"""
        
        try:
            self.total_requests += 1
            prompt = self._format_messages_for_gigachat(messages)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –≤ executor
            import asyncio
            loop = asyncio.get_event_loop()
            
            def sync_invoke():
                return self.gigachat.invoke(prompt)
            
            response = await loop.run_in_executor(None, sync_invoke)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
            content = response.content if hasattr(response, 'content') else str(response)
            estimated_tokens = len(prompt.split()) + len(content.split())
            self.total_tokens += estimated_tokens
            
            return LLMResponse(
                content=content,
                finish_reason="stop",
                usage={"total_tokens": estimated_tokens, "estimated": True},
                model=model or self.config.model,
                created=datetime.now()
            )
                
        except Exception as e:
            self.error_count += 1
            raise LLMError(f"–û—à–∏–±–∫–∞ GigaChat: {str(e)}")
    
    def _format_messages_for_gigachat(self, messages: List[LLMMessage]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –µ–¥–∏–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è GigaChat"""
        formatted_parts = []
        
        for message in messages:
            role = message.role
            content = message.content
            
            if role == "system":
                formatted_parts.append(f"–°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {content}")
            elif role == "user":
                formatted_parts.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {content}")
            elif role == "assistant":
                formatted_parts.append(f"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {content}")
            else:
                formatted_parts.append(content)
        
        return "\n\n".join(formatted_parts)
    
    async def extract_structured_data(
        self,
        data_to_analyze: str,
        extraction_prompt: str,
        expected_format: str = "JSON",
        max_attempts: int = 2
    ) -> Dict[str, Any]:
        """–ò–°–ü–†–ê–í–õ–ï–ù–û: –í–∫–ª—é—á–∞–µ–º extract_structured_data –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
        
        # –í–ê–ñ–ù–û: –ù–µ –æ—Ç–∫–ª—é—á–∞–µ–º –±–æ–ª—å—à–µ —ç—Ç–æ—Ç –º–µ—Ç–æ–¥!
        print(f"üîç GIGACHAT: extract_structured_data –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π")
        
        system_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö. 

        –¢–≤–æ—è –∑–∞–¥–∞—á–∞: {extraction_prompt}

        –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
        - –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º {expected_format} –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        - –ù–ï –¥–æ–±–∞–≤–ª—è–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –ø–æ—è—Å–Ω–µ–Ω–∏—è, —Ç–µ–≥–∏ <think> –∏–ª–∏ markdown –±–ª–æ–∫–∏
        - –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–π —Ä–∞–∑—É–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        - –°—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–∞–Ω–Ω—ã—Ö
        - –í—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–∞–º–∏, –Ω–µ —Å—Ç—Ä–æ–∫–∞–º–∏
        - –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–æ–ª–∂–Ω—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
        - –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –∑–∞–ø—è—Ç—ã–µ –≤ –∫–æ–Ω—Ü–µ –æ–±—ä–µ–∫—Ç–æ–≤ –∏–ª–∏ –º–∞—Å—Å–∏–≤–æ–≤

        –°–¢–†–û–ì–û: –æ—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON, –Ω–∞—á–∏–Ω–∞—é—â–∏–π—Å—è —Å {{ –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∏–π—Å—è }}"""

        last_error = None
        
        for attempt in range(max_attempts):
            try:
                messages = [
                    {"role": "user", "content": f"{system_prompt}\n\n–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:\n{data_to_analyze}"}
                ]
                
                print(f"üß† GIGACHAT –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})")
                
                # –í—ã–∑–æ–≤ GigaChat
                import asyncio
                loop = asyncio.get_event_loop()
                
                def sync_invoke():
                    prompt = f"{system_prompt}\n\n–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:\n{data_to_analyze}"
                    return self.gigachat.invoke(prompt)
                
                response = await loop.run_in_executor(None, sync_invoke)
                raw_content = response.content if hasattr(response, 'content') else str(response)
                
                print(f"üß† GIGACHAT –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø: –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {len(raw_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å JSON
                parsed_data = self._parse_gigachat_response(raw_content)
                validated_data = self._validate_gigachat_response(parsed_data, "")
                
                print(f"üß† GIGACHAT –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø: ‚úÖ –£—Å–ø–µ—à–Ω–æ")
                return validated_data
                
            except Exception as e:
                last_error = e
                print(f"üß† GIGACHAT –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø: ‚ùå –û—à–∏–±–∫–∞ - {e}")
                
                if attempt < max_attempts - 1:
                    await asyncio.sleep(1 + attempt)
                else:
                    return self._create_emergency_fallback_result(extraction_prompt, str(e))
        
        return self._create_emergency_fallback_result(extraction_prompt, str(last_error))
    
    async def evaluate_risk(
        self,
        risk_type: str,
        agent_data: str,
        evaluation_criteria: str,
        examples: Optional[str] = None
    ) -> Dict[str, Any]:
        """–£–õ–£–ß–®–ï–ù–ù–ê–Ø –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞ —Å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è–º–∏ –¥–ª—è GigaChat"""
        
        print(f"üß† –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø –ê–ì–ï–ù–¢–ê: –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ {risk_type}")
        print(f"üß† –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø –ê–ì–ï–ù–¢–ê: –ò–∑—É—á–∞—é –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞...")
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è GigaChat —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
        system_prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ü–µ–Ω–∫–µ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ –≤ –±–∞–Ω–∫–æ–≤—Å–∫–æ–π —Å—Ñ–µ—Ä–µ. 

üéØ –ó–ê–î–ê–ß–ê: –û—Ü–µ–Ω–∏—Ç—å {risk_type} –¥–ª—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞

üìã –ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò: {evaluation_criteria}

üß† –í–ê–ñ–ù–û: –°–Ω–∞—á–∞–ª–∞ –ü–û–î–†–û–ë–ù–û —Ä–∞—Å—Å—É–∂–¥–∞–π –≤—Å–ª—É—Ö:
1. –û–ø–∏—à–∏ —á—Ç–æ —Ç—ã –≤–∏–¥–∏—à—å –≤ –¥–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞
2. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è—é—Ç –Ω–∞ –¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–∏—Å–∫–∞
3. –û–±—ä—è—Å–Ω–∏ –ø–æ—á–µ–º—É –≤—ã–±–∏—Ä–∞–µ—à—å —Ç–∞–∫—É—é –æ—Ü–µ–Ω–∫—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (1-5)
4. –û–±–æ—Å–Ω—É–π –ø–æ—á–µ–º—É –≤—ã–±–∏—Ä–∞–µ—à—å —Ç–∞–∫—É—é –æ—Ü–µ–Ω–∫—É –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è (1-5)
5. –ü—Ä–µ–¥–ª–æ–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–ü–æ—Å–ª–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –¥–∞–π –¢–û–õ–¨–ö–û —á–∏—Å—Ç—ã–π JSON (–±–µ–∑ markdown):
{{
    "probability_score": —á–∏—Å–ª–æ_–æ—Ç_1_–¥–æ_5,
    "impact_score": —á–∏—Å–ª–æ_–æ—Ç_1_–¥–æ_5,
    "total_score": –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_—É–º–Ω–æ–∂–∏—Ç—å_–Ω–∞_–≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ,
    "risk_level": "low_–∏–ª–∏_medium_–∏–ª–∏_high",
    "probability_reasoning": "–∫—Ä–∞—Ç–∫–æ–µ_–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏",
    "impact_reasoning": "–∫—Ä–∞—Ç–∫–æ–µ_–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ_–≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è",
    "key_factors": ["–∫–ª—é—á–µ–≤–æ–π_—Ñ–∞–∫—Ç–æ—Ä1", "–∫–ª—é—á–µ–≤–æ–π_—Ñ–∞–∫—Ç–æ—Ä2"],
    "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è1", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è2"],
    "confidence_level": —á–∏—Å–ª–æ_–æ—Ç_0.0_–¥–æ_1.0
}}"""

        try:
            print(f"üß† –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø –ê–ì–ï–ù–¢–ê: –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏...")
            
            # –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ GigaChat
            import asyncio
            loop = asyncio.get_event_loop()
            
            def sync_invoke():
                prompt = f"{system_prompt}\n\nüìä –î–ê–ù–ù–´–ï –ê–ì–ï–ù–¢–ê:\n{agent_data[:1500]}"
                return self.gigachat.invoke(prompt)
            
            response = await loop.run_in_executor(None, sync_invoke)
            raw_content = response.content if hasattr(response, 'content') else str(response)
            
            print(f"üß† –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø –ê–ì–ï–ù–¢–ê: –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {len(raw_content)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            reasoning_shown = False
            if len(raw_content) > 100:
                # –ò—â–µ–º –≥–¥–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è JSON
                json_start = raw_content.find('{')
                
                if json_start > 100:  # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥ JSON –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ–∫—Å—Ç–∞ - —ç—Ç–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
                    reasoning_text = raw_content[:json_start].strip()
                    json_part = raw_content[json_start:]
                    
                    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏–∑ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
                    reasoning_text = reasoning_text.replace('```', '').replace('json', '').strip()
                    
                    if reasoning_text and len(reasoning_text) > 50:
                        print(f"\n{'='*70}")
                        print(f"üß† –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø –ê–ì–ï–ù–¢–ê –ü–û –¢–ò–ü–£ –†–ò–°–ö–ê: {risk_type.upper()}")
                        print(f"{'='*70}")
                        print(reasoning_text)
                        print(f"{'='*70}\n")
                        reasoning_shown = True
                    
                    # –ü–∞—Ä—Å–∏–º —Ç–æ–ª—å–∫–æ JSON —á–∞—Å—Ç—å
                    try:
                        parsed_data = self._parse_gigachat_response(json_part)
                    except:
                        parsed_data = self._parse_gigachat_response(raw_content)
                else:
                    parsed_data = self._parse_gigachat_response(raw_content)
            else:
                parsed_data = self._parse_gigachat_response(raw_content)
            
            if not reasoning_shown:
                print(f"üß† –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø –ê–ì–ï–ù–¢–ê: ‚ö†Ô∏è  –†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –æ—Ç–≤–µ—Ç–µ")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∞–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            validated_data = self._validate_gigachat_response(parsed_data, risk_type)
            
            print(f"üß† –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø –ê–ì–ï–ù–¢–ê: ‚úÖ –ê–Ω–∞–ª–∏–∑ {risk_type} –∑–∞–≤–µ—Ä—à–µ–Ω")
            
            return validated_data
            
        except Exception as e:
            print(f"üß† –†–ê–°–°–£–ñ–î–ï–ù–ò–Ø –ê–ì–ï–ù–¢–ê: ‚ùå –û—à–∏–±–∫–∞ - {e}")
            # Fallback
            return self._create_fallback_response(risk_type, f"–û—à–∏–±–∫–∞ GigaChat: {e}")
    
    def _parse_gigachat_response(self, content: str) -> Dict[str, Any]:
        """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ GigaChat"""
        
        import json
        import re
        
        # –û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content = content.strip()
        
        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã/—Å—É—Ñ—Ñ–∏–∫—Å—ã
        content = re.sub(r'^.*?({.*}).*$', r'\1', content, flags=re.DOTALL)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω JSON, –∏—â–µ–º –¥—Ä—É–≥–∏–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
        if not content.startswith('{'):
            # –ü–æ–∏—Å–∫ JSON –±–ª–æ–∫–∞
            json_match = re.search(r'{[^{}]*(?:{[^{}]*}[^{}]*)*}', content, re.DOTALL)
            if json_match:
                content = json_match.group()
            else:
                raise ValueError(f"–ù–µ –Ω–∞–π–¥–µ–Ω JSON –≤ –æ—Ç–≤–µ—Ç–µ: {content[:100]}")
        
        try:
            # –ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥
            return json.loads(content)
        except json.JSONDecodeError as e:
            print(f"üîç GIGACHAT DEBUG: –û—à–∏–±–∫–∞ JSON –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            print(f"üîç GIGACHAT DEBUG: –ü—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {content}")
            
            # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø—Ä–∞–≤–∏—Ç—å JSON
            fixed_content = self._fix_json_for_gigachat(content)
            return json.loads(fixed_content)
    
    def _fix_json_for_gigachat(self, content: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ JSON —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è GigaChat"""
        
        import re
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        content = re.sub(r',\s*}', '}', content)  # –£–¥–∞–ª—è–µ–º trailing comma
        content = re.sub(r',\s*]', ']', content)  # –£–¥–∞–ª—è–µ–º trailing comma –≤ –º–∞—Å—Å–∏–≤–∞—Ö
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏ –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º –±–µ–∑ –∫–∞–≤—ã—á–µ–∫
        content = re.sub(r':\s*([^",{\[\]\s][^,}\]]*[^",}\]\s])\s*[,}]', 
                        lambda m: f': "{m.group(1).strip()}"' + m.group(0)[-1], content)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –±—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è
        content = re.sub(r':\s*true', ': "true"', content)
        content = re.sub(r':\s*false', ': "false"', content)
        
        return content
    
    def _validate_gigachat_response(self, data: Dict[str, Any], risk_type: str) -> Dict[str, Any]:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º key_factors"""
        
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è —Å —É–º–Ω—ã–º–∏ –¥–µ—Ñ–æ–ª—Ç–∞–º–∏
        defaults = {
            "probability_score": 3,
            "impact_score": 3,
            "total_score": 9,
            "risk_level": "medium",
            "probability_reasoning": f"GigaChat –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ {risk_type}",
            "impact_reasoning": f"GigaChat –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è {risk_type}",
            "key_factors": [],
            "recommendations": [f"–ü—Ä–æ–≤–µ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ {risk_type}", "–£–ª—É—á—à–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"],
            "confidence_level": 0.7
        }
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è
        for field, default in defaults.items():
            if field not in data or not data[field]:
                data[field] = default
                print(f"üîß GIGACHAT: –ü–æ–ª–µ {field} –∑–∞–º–µ–Ω–µ–Ω–æ –Ω–∞ –¥–µ—Ñ–æ–ª—Ç: {default}")
        
        # –ù–û–í–û–ï: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ key_factors
        if not data["key_factors"] or len(data["key_factors"]) == 0:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–∫—Ç–æ—Ä—ã –∏–∑ reasoning –ø–æ–ª–µ–π
            factors = []
            
            # –ò—â–µ–º –≤ probability_reasoning
            prob_text = str(data.get("probability_reasoning", "")).lower()
            if "–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω" in prob_text and "–∑–∞—â–∏—Ç" in prob_text:
                factors.append("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ –º–µ—Ä—ã –∑–∞—â–∏—Ç—ã")
            if "guardrails" in prob_text:
                factors.append("–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ guardrails")
            if "–∞–≤—Ç–æ–Ω–æ–º" in prob_text:
                factors.append("–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏")
            if "–∏–Ω—Ç–µ–≥—Ä–∞—Ü" in prob_text:
                factors.append("–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ API")
            if "–¥–∞–Ω–Ω—ã" in prob_text and "–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω" in prob_text:
                factors.append("–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            
            # –ò—â–µ–º –≤ impact_reasoning
            impact_text = str(data.get("impact_reasoning", "")).lower()
            if "—Ä–µ–ø—É—Ç–∞—Ü" in impact_text:
                factors.append("–†–µ–ø—É—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏")
            if "—é—Ä–∏–¥–∏—á–µ—Å–∫" in impact_text:
                factors.append("–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è")
            if "—à—Ç—Ä–∞—Ñ" in impact_text:
                factors.append("–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ—Ç–µ—Ä–∏")
            if "–¥–æ–≤–µ—Ä–∏–µ" in impact_text:
                factors.append("–ü–æ—Ç–µ—Ä—è –¥–æ–≤–µ—Ä–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
            
            # –ï—Å–ª–∏ –∏–∑–≤–ª–µ–∫–ª–∏ —Ñ–∞–∫—Ç–æ—Ä—ã, –æ–±–Ω–æ–≤–ª—è–µ–º
            if factors:
                data["key_factors"] = factors[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 —Ñ–∞–∫—Ç–æ—Ä–æ–≤
                print(f"üîß GIGACHAT: –ò–∑–≤–ª–µ—á–µ–Ω—ã key_factors: {factors}")
            else:
                # Fallback —Ñ–∞–∫—Ç–æ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ risk_type
                fallback_factors = {
                    "ethical": ["–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è", "–≠—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è"],
                    "social": ["–ú–∞–Ω–∏–ø—É–ª—è—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏", "–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"],
                    "security": ["–£—è–∑–≤–∏–º–æ—Å—Ç–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", "–£—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö"],
                    "stability": ["–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", "–û—à–∏–±–∫–∏ –≤ –æ—Ç–≤–µ—Ç–∞—Ö"],
                    "autonomy": ["–ù–µ–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è", "–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–º–æ—á–∏–π"],
                    "regulatory": ["–ù–∞—Ä—É—à–µ–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π", "–®—Ç—Ä–∞—Ñ–Ω—ã–µ —Å–∞–Ω–∫—Ü–∏–∏"]
                }
                data["key_factors"] = fallback_factors.get(risk_type, ["–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞"])
        
        # –û—Å—Ç–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è...
        try:
            data["probability_score"] = max(1, min(5, int(float(str(data["probability_score"])))))
            data["impact_score"] = max(1, min(5, int(float(str(data["impact_score"])))))
            data["total_score"] = data["probability_score"] * data["impact_score"]
        except (ValueError, TypeError) as e:
            print(f"üîß GIGACHAT: –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —á–∏—Å–µ–ª: {e}")
            data["probability_score"] = 3
            data["impact_score"] = 3
            data["total_score"] = 9
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è risk_level
        valid_levels = ["low", "medium", "high"]
        if data.get("risk_level") not in valid_levels:
            score = data["total_score"]
            if score <= 6:
                data["risk_level"] = "low"
            elif score <= 14:
                data["risk_level"] = "medium"
            else:
                data["risk_level"] = "high"
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–ø–∏—Å–∫–æ–≤
        if not isinstance(data.get("recommendations"), list):
            data["recommendations"] = [f"–£–ª—É—á—à–∏—Ç—å –∞–Ω–∞–ª–∏–∑ {risk_type}"]
        
        if not isinstance(data.get("key_factors"), list):
            data["key_factors"] = []
        
        return data
    
    def _create_fallback_response(self, risk_type: str, error_msg: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ fallback –æ—Ç–≤–µ—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        
        return {
            "probability_score": 3,
            "impact_score": 3,
            "total_score": 9,
            "risk_level": "medium",
            "probability_reasoning": f"Fallback –æ—Ü–µ–Ω–∫–∞ –¥–ª—è {risk_type}: {error_msg}",
            "impact_reasoning": f"Fallback –æ—Ü–µ–Ω–∫–∞ –¥–ª—è {risk_type}: {error_msg}",
            "key_factors": ["–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ—Ç GigaChat"],
            "recommendations": [f"–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –æ—Ü–µ–Ω–∫—É {risk_type}", "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ GigaChat"],
            "confidence_level": 0.3
        }
    
    async def critique_evaluation(
        self,
        risk_type: str,
        original_evaluation: Dict[str, Any],
        agent_data: str,
        quality_threshold: float = 7.0
    ) -> Dict[str, Any]:
        """–ö—Ä–∏—Ç–∏–∫–∞ –æ—Ü–µ–Ω–∫–∏ –¥—Ä—É–≥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ GigaChat"""
        
        system_prompt = f"""–¢—ã - –∫—Ä–∏—Ç–∏–∫-—ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ü–µ–Ω–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ {risk_type}.

–ö–†–ò–¢–ï–†–ò–ò –ö–ê–ß–ï–°–¢–í–ê:
1. –û–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–æ–∫ (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–∞–Ω–Ω—ã–º –∞–≥–µ–Ω—Ç–∞)
2. –ü–æ–ª–Ω–æ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ (—É—á—Ç–µ–Ω—ã –ª–∏ –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã)
3. –õ–æ–≥–∏—á–Ω–æ—Å—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
4. –ü—Ä–∞–∫—Ç–∏—á–Ω–æ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
5. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ—Ç–æ–¥–∏–∫–µ –æ—Ü–µ–Ω–∫–∏

–®–ö–ê–õ–ê –ö–ê–ß–ï–°–¢–í–ê: 0-10 –±–∞–ª–ª–æ–≤
–ü–û–†–û–ì –ü–†–ò–ï–ú–õ–ï–ú–û–°–¢–ò: {quality_threshold} –±–∞–ª–ª–æ–≤

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–°–¢–†–û–ì–û JSON):
{{
    "quality_score": <0.0-10.0>,
    "is_acceptable": <true|false>,
    "issues_found": ["<–ø—Ä–æ–±–ª–µ–º–∞1>", "<–ø—Ä–æ–±–ª–µ–º–∞2>", ...],
    "improvement_suggestions": ["<–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ1>", "<–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ2>", ...],
    "critic_reasoning": "<–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞>"
}}"""

        evaluation_text = json.dumps(original_evaluation, ensure_ascii=False, indent=2)
        
        context = f"""–î–ê–ù–ù–´–ï –û–ë –ê–ì–ï–ù–¢–ï:
{agent_data}

–û–¶–ï–ù–ö–ê –î–õ–Ø –ö–†–ò–¢–ò–ö–ò:
{evaluation_text}"""

        response = await self.extract_structured_data(
            data_to_analyze=context,
            extraction_prompt="–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞",
            expected_format="JSON"
        )
        
        # –ê–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        if "quality_score" not in response:
            response["quality_score"] = 7.0
        if "is_acceptable" not in response:
            response["is_acceptable"] = response["quality_score"] >= quality_threshold
        if "critic_reasoning" not in response:
            response["critic_reasoning"] = "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞"
        
        return response
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ GigaChat"""
        pass


# ===============================
# –§–∞–±—Ä–∏–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤
# ===============================

def create_llm_client(
    client_type: str = "standard",
    base_url: Optional[str] = None,
    model: Optional[str] = None,
    temperature: Optional[float] = None
) -> LLMClient:
    """
    –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è LLM –∫–ª–∏–µ–Ω—Ç–æ–≤
    –û–ë–ù–û–í–õ–ï–ù–û: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ GigaChat
    """
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
    overrides = {}
    if base_url is not None:
        overrides['base_url'] = base_url
    if model is not None:
        overrides['model'] = model
    if temperature is not None:
        overrides['temperature'] = temperature
    
    config = LLMConfig.from_manager(**overrides)
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–æ–π –∫–ª–∏–µ–Ω—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –° –£–ß–ï–¢–û–ú client_type
    if config.provider == LLMProvider.GIGACHAT:
        # –î–ª—è GigaChat —É—á–∏—Ç—ã–≤–∞–µ–º —Ç–∏–ø –∫–ª–∏–µ–Ω—Ç–∞
        if client_type == "risk_analysis":
            return GigaChatRiskAnalysisLLMClient(config)
        else:
            return GigaChatLLMClient(config)
    else:
        # –î–ª—è LM Studio –∏ OpenAI –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã
        if client_type == "risk_analysis":
            return RiskAnalysisLLMClient(config)
        else:
            return LLMClient(config)


# ===============================
# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
# ===============================

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
_global_client: Optional[LLMClient] = None

async def get_llm_client() -> LLMClient:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ LLM –∫–ª–∏–µ–Ω—Ç–∞
    –û–ë–ù–û–í–õ–ï–ù–û: –£–ª—É—á—à–µ–Ω–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫
    """
    global _global_client
    
    if _global_client is None:
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            config = LLMConfig.from_manager()
            
            print(f"üîß –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM:")
            print(f"   –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {config.provider.value}")
            print(f"   URL: {config.base_url}")
            print(f"   –ú–æ–¥–µ–ª—å: {config.model}")
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            if config.provider == LLMProvider.GIGACHAT:
                print("ü§ñ –°–æ–∑–¥–∞–µ–º GigaChat –∫–ª–∏–µ–Ω—Ç...")
                _global_client = GigaChatLLMClient(config)
            else:
                print(f"ü§ñ –°–æ–∑–¥–∞–µ–º {config.provider.value} –∫–ª–∏–µ–Ω—Ç...")
                _global_client = LLMClient(config)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
            print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM —Å–µ—Ä–≤–µ—Ä–∞...")
            is_available = await _global_client.health_check()
            
            if not is_available:
                provider_name = config.provider.value
                error_msg = f"{provider_name} —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è."
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –¥–ª—è GigaChat
                if config.provider == LLMProvider.GIGACHAT:
                    error_msg += f"\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\n- –°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã: {config.cert_file}, {config.key_file}\n- URL: {config.base_url}"
                else:
                    error_msg += f"\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\n- URL: {config.base_url}\n- –ó–∞–ø—É—â–µ–Ω –ª–∏ —Å–µ—Ä–≤–µ—Ä?"
                
                raise LLMError(error_msg)
            
            print(f"‚úÖ {config.provider.value} –∫–ª–∏–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω")
            
        except Exception as e:
            print("‚ùå –û–®–ò–ë–ö–ê –°–û–ó–î–ê–ù–ò–Ø LLM –ö–õ–ò–ï–ù–¢–ê:")
            print(f"   {str(e)}")
            print("\nüîç –ó–∞–ø—É—Å–∫–∞–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É...")
            print_llm_diagnosis()
            raise e
    
    return _global_client

def reset_global_client():
    """
    –°–±—Ä–æ—Å –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –∏–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    """
    global _global_client
    _global_client = None


def force_recreate_global_client():
    """
    –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
    –ü–æ–ª–µ–∑–Ω–æ –ø—Ä–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
    """
    global _global_client
    _global_client = None    

def diagnose_llm_configuration() -> Dict[str, Any]:
    """
    –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LLM –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    """
    import os
    
    diagnosis = {
        "environment_variables": {},
        "config_manager_info": {},
        "files_exist": {},
        "errors": []
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    env_vars = [
        "LLM_PROVIDER", "GIGACHAT_BASE_URL", "GIGACHAT_MODEL",
        "GIGACHAT_CERT_PATH", "GIGACHAT_KEY_PATH", "LLM_TEMPERATURE"
    ]
    
    for var in env_vars:
        diagnosis["environment_variables"][var] = os.getenv(var, "–ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù–ê")
    
    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    try:
        manager = get_llm_config_manager()
        diagnosis["config_manager_info"] = manager.get_info()
    except Exception as e:
        diagnosis["errors"].append(f"–û—à–∏–±–∫–∞ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {str(e)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ –¥–ª—è GigaChat
    if os.getenv("LLM_PROVIDER", "").lower() == "gigachat":
        cert_path = os.getenv("GIGACHAT_CERT_PATH", "")
        key_path = os.getenv("GIGACHAT_KEY_PATH", "")
        
        if cert_path:
            if not os.path.isabs(cert_path):
                cert_path = os.path.join(os.getcwd(), cert_path)
            diagnosis["files_exist"]["cert_file"] = os.path.exists(cert_path)
            diagnosis["files_exist"]["cert_path"] = cert_path
            
        if key_path:
            if not os.path.isabs(key_path):
                key_path = os.path.join(os.getcwd(), key_path)
            diagnosis["files_exist"]["key_file"] = os.path.exists(key_path) 
            diagnosis["files_exist"]["key_path"] = key_path
    
    return diagnosis


def print_llm_diagnosis():
    """–í—ã–≤–æ–¥–∏—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LLM –≤ –∫–æ–Ω—Å–æ–ª—å"""
    import json
    diagnosis = diagnose_llm_configuration()
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò LLM:")
    print(json.dumps(diagnosis, ensure_ascii=False, indent=2))

async def test_gigachat_direct() -> Dict[str, Any]:
    """
    –ü—Ä—è–º–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GigaChat –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    """
    print("üß™ –ü–†–Ø–ú–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï GIGACHAT")
    print("=" * 50)
    
    result = {
        "success": False,
        "error": None,
        "response": None,
        "config_info": {},
        "certificate_check": {}
    }
    
    try:
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        from .llm_config_manager import get_llm_config_manager
        manager = get_llm_config_manager()
        config_info = manager.get_info()
        result["config_info"] = config_info
        
        print(f"üìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
        print(f"   Provider: {config_info['provider']}")
        print(f"   URL: {config_info['base_url']}")
        print(f"   Model: {config_info['model']}")
        print(f"   Cert: {config_info.get('cert_file', '–Ω–µ —É–∫–∞–∑–∞–Ω')}")
        print(f"   Key: {config_info.get('key_file', '–Ω–µ —É–∫–∞–∑–∞–Ω')}")
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã
        import os
        cert_exists = os.path.exists(config_info.get('cert_file', ''))
        key_exists = os.path.exists(config_info.get('key_file', ''))
        
        result["certificate_check"] = {
            "cert_exists": cert_exists,
            "key_exists": key_exists,
            "cert_path": config_info.get('cert_file'),
            "key_path": config_info.get('key_file')
        }
        
        print(f"üîí –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤:")
        print(f"   Cert —Ñ–∞–π–ª: {'‚úÖ' if cert_exists else '‚ùå'}")
        print(f"   Key —Ñ–∞–π–ª: {'‚úÖ' if key_exists else '‚ùå'}")
        
        if not (cert_exists and key_exists):
            result["error"] = "–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            return result
        
        # 3. –°–æ–∑–¥–∞–µ–º GigaChat –∫–ª–∏–µ–Ω—Ç –Ω–∞–ø—Ä—è–º—É—é
        print("ü§ñ –°–æ–∑–¥–∞–µ–º GigaChat –∫–ª–∏–µ–Ω—Ç...")
        
        if not GIGACHAT_AVAILABLE:
            result["error"] = "langchain_gigachat –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
            return result
        
        gigachat = GigaChat(
            base_url=config_info['base_url'],
            cert_file=config_info['cert_file'],
            key_file=config_info['key_file'],
            model=config_info['model'],
            temperature=config_info['temperature'],
            top_p=config_info.get('top_p', 0.2),
            verify_ssl_certs=config_info.get('verify_ssl_certs', False),
            profanity_check=config_info.get('profanity_check', False),
            streaming=config_info.get('streaming', True)
        )
        
        print("‚úÖ GigaChat –∫–ª–∏–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω")
        
        # 4. –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—ã–∑–æ–≤
        print("üìû –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—ã–∑–æ–≤ GigaChat...")
        
        import asyncio
        loop = asyncio.get_event_loop()
        
        def sync_call():
            return gigachat.invoke("–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ.")
        
        response = await loop.run_in_executor(None, sync_call)
        
        print(f"üì® –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç: {type(response)}")
        
        if hasattr(response, 'content'):
            content = response.content
            print(f"üìù –°–æ–¥–µ—Ä–∂–∏–º–æ–µ: '{content}'")
            result["response"] = {
                "type": str(type(response)),
                "content": content,
                "has_content": True,
                "content_length": len(content) if content else 0
            }
        else:
            print(f"‚ö†Ô∏è –û—Ç–≤–µ—Ç –±–µ–∑ –∞—Ç—Ä–∏–±—É—Ç–∞ content: {response}")
            result["response"] = {
                "type": str(type(response)),
                "content": str(response),
                "has_content": False,
                "raw_response": str(response)
            }
        
        result["success"] = True
        print("üéâ –¢–ï–°–¢ –ü–†–û–®–ï–õ –£–°–ü–ï–®–ù–û!")
        
    except Exception as e:
        result["error"] = str(e)
        result["exception_type"] = type(e).__name__
        print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
        print(f"‚ùå –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e)}")
        
        import traceback
        print(f"‚ùå Traceback: {traceback.format_exc()}")
    
    return result
__all__ = [
    "LLMClient",
    "GigaChatLLMClient",
    "GigaChatRiskAnalysisLLMClient",  # ‚Üê –ù–û–í–´–ô –ö–õ–ê–°–°
    "RiskAnalysisLLMClient", 
    "LLMConfig",
    "LLMMessage",
    "LLMResponse",
    "LLMError",
    "create_llm_client",
    "get_llm_client",
    "reset_global_client", 
    "force_recreate_global_client",
    "diagnose_llm_configuration",
    "print_llm_diagnosis",
    "test_gigachat_direct"
]