# src/workflow/graph_builder.py
"""
LangGraph workflow –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤
–°–æ–∑–¥–∞–µ—Ç –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–π –≥—Ä–∞—Ñ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ—Ü–µ–Ω–∫–∏
"""

import asyncio
from typing import Dict, Any, List, Optional, Literal
from datetime import datetime

from langgraph.graph import StateGraph, END
from langgraph.graph.graph import CompiledGraph

from ..models.risk_models import (
    WorkflowState, RiskType, ProcessingStatus, AgentRiskAssessment,
    AgentProfile, AgentTaskResult
)
from ..agents.profiler_agent import create_profiler_agent, create_profiler_node_function
from ..agents.evaluator_agents import (
    create_all_evaluator_agents, create_evaluator_nodes_for_langgraph_safe,
    extract_risk_evaluations_from_results, calculate_overall_risk_score,
    get_highest_risk_areas, create_critic_node_function_fixed
)
from ..agents.critic_agent import (
    create_critic_agent, create_quality_check_router
)
from ..agents.evaluator_agents import create_critic_node_function_fixed
from ..utils.logger import get_langgraph_logger, log_graph_node, log_conditional_edge_func
from ..models.database import get_db_manager


class RiskAssessmentWorkflow:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π workflow –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤
    
    –ì—Ä–∞—Ñ –≤–∫–ª—é—á–∞–µ—Ç:
    1. –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
    2. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ 6 —Ç–∏–ø–æ–≤ —Ä–∏—Å–∫–æ–≤  
    3. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
    4. –ü–æ–≤—Ç–æ—Ä—ã –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    5. –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    """
    
    def __init__(
        self,
        llm_base_url: str = "http://127.0.0.1:1234",
        llm_model: str = "qwen3-4b",
        quality_threshold: float = 7.0,
        max_retries: int = 3
    ):
        self.llm_base_url = llm_base_url
        self.llm_model = llm_model
        self.quality_threshold = quality_threshold
        self.max_retries = max_retries
        
        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤
        self.profiler = create_profiler_agent(llm_base_url, llm_model)
        self.evaluators = create_all_evaluator_agents(llm_base_url, llm_model)
        self.critic = create_critic_agent(llm_base_url, llm_model, quality_threshold)
        
        # –õ–æ–≥–≥–µ—Ä –¥–ª—è LangGraph
        self.graph_logger = get_langgraph_logger()
        
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ
        self.graph = self._build_graph()
    
    def _build_graph(self) -> CompiledGraph:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ LangGraph workflow"""
        
        # –°–æ–∑–¥–∞–µ–º StateGraph
        workflow = StateGraph(WorkflowState)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —É–∑–ª—ã
        self._add_nodes(workflow)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä—ë–±—Ä–∞
        self._add_edges(workflow)
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –∏ –≤—ã—Ö–æ–¥–∞
        workflow.set_entry_point("initialization")
        workflow.set_finish_point("finalization")
        
        return workflow.compile()
    
    def _add_nodes(self, workflow: StateGraph):
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤ —Å –±–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –æ—Ü–µ–Ω—â–∏–∫–∞–º–∏"""
        
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        workflow.add_node("initialization", self._initialization_node)
        
        # 2. –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
        profiler_node = create_profiler_node_function(self.profiler)
        workflow.add_node("profiling", log_graph_node("profiling")(profiler_node))
        
        # 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ—Ü–µ–Ω–∫–µ
        workflow.add_node("evaluation_preparation", self._evaluation_preparation_node)
        
        # 4. –ù–û–í–´–ï –ë–ê–¢–ß–ò–†–û–í–ê–ù–ù–´–ï –£–ó–õ–´ –û–¶–ï–ù–ö–ò
        workflow.add_node("batch_1_evaluation", self._batch_1_evaluation_node)
        workflow.add_node("batch_2_evaluation", self._batch_2_evaluation_node) 
        workflow.add_node("batch_3_evaluation", self._batch_3_evaluation_node)
        
        # 5. –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        workflow.add_node("evaluation_collection", self._evaluation_collection_node)
        
        # 6. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        critic_node = create_critic_node_function_fixed(self.critic)
        workflow.add_node("critic_analysis", log_graph_node("critic_analysis")(critic_node))
        
        # 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        workflow.add_node("quality_check", self._quality_check_node)
        
        # 8. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        workflow.add_node("retry_evaluation", self._retry_evaluation_node)
        
        # 9. –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è
        workflow.add_node("finalization", self._finalization_node)
        
        # 10. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
        workflow.add_node("error_handling", self._error_handling_node)
    
    def _add_edges(self, workflow: StateGraph):
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä—ë–±–µ—Ä —Å –±–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∞–≥–µ–Ω—Ç–æ–≤"""
        
        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã
        workflow.add_edge("initialization", "profiling")
        workflow.add_edge("profiling", "evaluation_preparation")
        
        # –ù–û–í–û–ï: –ë–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤ (–ø–æ 2 –∞–≥–µ–Ω—Ç–∞ –∑–∞ —Ä–∞–∑)
        
        # –ë–∞—Ç—á 1: –≠—Ç–∏—á–µ—Å–∫–∏–µ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏
        workflow.add_edge("evaluation_preparation", "batch_1_evaluation")
        
        # –ë–∞—Ç—á 2: –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å  
        workflow.add_edge("batch_1_evaluation", "batch_2_evaluation")
        
        # –ë–∞—Ç—á 3: –ê–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å –∏ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ
        workflow.add_edge("batch_2_evaluation", "batch_3_evaluation")
        
        # –ü–æ—Å–ª–µ –≤—Å–µ—Ö –±–∞—Ç—á–µ–π - —Å–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        workflow.add_edge("batch_3_evaluation", "evaluation_collection")
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –æ—Å—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–∂–Ω–∏–º
        
        workflow.add_edge("critic_analysis", "quality_check")
        
        # –£—Å–ª–æ–≤–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã –∏–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        workflow.add_conditional_edges(
            "quality_check",
            log_conditional_edge_func("quality_check_router")(self._quality_check_router),
            {
                "retry": "retry_evaluation",
                "finalize": "finalization",
                "error": "error_handling",
                "critic": "critic_analysis"
            }
        )
        # –ö—Ä–∏—Ç–∏–∫ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        workflow.add_edge("critic_analysis", "quality_check")  # –í–æ–∑–≤—Ä–∞—Ç –∫ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞
        # –ò–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –æ–±—Ä–∞—Ç–Ω–æ –∫ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ
        workflow.add_edge("retry_evaluation", "evaluation_preparation")
        
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        workflow.add_edge("finalization", END)
        workflow.add_edge("error_handling", END)
    
    # ===============================
    # –£–∑–ª—ã –≥—Ä–∞—Ñ–∞
    # ===============================
    
    @log_graph_node("batch_1_evaluation")
    async def _batch_1_evaluation_node(self, state: WorkflowState) -> WorkflowState:
        """–ë–∞—Ç—á 1: –≠—Ç–∏—á–µ—Å–∫–∏–µ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)"""
        
        assessment_id = state["assessment_id"]
        agent_profile = state.get("agent_profile", {})
        
        self.graph_logger.log_workflow_step(
            assessment_id, 
            "batch_1_evaluation", 
            "–ó–∞–ø—É—Å–∫ –ë–∞—Ç—á–∞ 1: —ç—Ç–∏—á–µ—Å–∫–∏–µ + —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏"
        )
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        input_data = {"agent_profile": agent_profile}
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º 2 –∞–≥–µ–Ω—Ç–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            ethical_task = self.evaluators[RiskType.ETHICAL].run(input_data, assessment_id)
            social_task = self.evaluators[RiskType.SOCIAL].run(input_data, assessment_id)
            
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±–æ–∏—Ö
            ethical_result, social_result = await asyncio.gather(
                ethical_task, social_task, return_exceptions=True
            )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if not isinstance(ethical_result, Exception):
                state.set_evaluation_result("ethical", ethical_result)
                self.graph_logger.log_workflow_step(
                    assessment_id, "batch_1_ethical", 
                    f"–≠—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏: {ethical_result.status}"
                )
            else:
                state.set_evaluation_result("ethical", self._create_error_result(
                    "ethical_risk_evaluator", str(ethical_result)
                ))
            
            if not isinstance(social_result, Exception):
                state.set_evaluation_result("social", social_result)
                self.graph_logger.log_workflow_step(
                    assessment_id, "batch_1_social",
                    f"–°–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏: {social_result.status}"
                )
            else:
                state.set_evaluation_result("social", self._create_error_result(
                    "social_risk_evaluator", str(social_result)
                ))
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –±–∞—Ç—á–µ–º
            await asyncio.sleep(2)
            
        except Exception as e:
            self.graph_logger.log_workflow_step(
                assessment_id, "batch_1_error", f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–∞ 1: {e}"
            )
            
            # –°–æ–∑–¥–∞–µ–º error —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ–±–æ–∏—Ö —Ç–∏–ø–æ–≤
            state.set_evaluation_result("ethical", self._create_error_result(
                "ethical_risk_evaluator", f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–∞: {e}"
            ))
            state.set_evaluation_result("social", self._create_error_result(
                "social_risk_evaluator", f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–∞: {e}"
            ))
        
        state["current_step"] = "batch_2_evaluation"
        return state

    @log_graph_node("batch_2_evaluation") 
    async def _batch_2_evaluation_node(self, state: WorkflowState) -> WorkflowState:
        """–ë–∞—Ç—á 2: –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)"""
        
        assessment_id = state["assessment_id"]
        agent_profile = state.get("agent_profile", {})
        
        self.graph_logger.log_workflow_step(
            assessment_id, 
            "batch_2_evaluation", 
            "–ó–∞–ø—É—Å–∫ –ë–∞—Ç—á–∞ 2: –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å + —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å"
        )
        
        input_data = {"agent_profile": agent_profile}
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º 2 –∞–≥–µ–Ω—Ç–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            security_task = self.evaluators[RiskType.SECURITY].run(input_data, assessment_id)
            stability_task = self.evaluators[RiskType.STABILITY].run(input_data, assessment_id)
            
            security_result, stability_result = await asyncio.gather(
                security_task, stability_task, return_exceptions=True
            )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if not isinstance(security_result, Exception):
                state.set_evaluation_result("security", security_result)
                self.graph_logger.log_workflow_step(
                    assessment_id, "batch_2_security",
                    f"–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: {security_result.status}"
                )
            else:
                state.set_evaluation_result("security", self._create_error_result(
                    "security_risk_evaluator", str(security_result)
                ))
            
            if not isinstance(stability_result, Exception):
                state.set_evaluation_result("stability", stability_result)
                self.graph_logger.log_workflow_step(
                    assessment_id, "batch_2_stability",
                    f"–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {stability_result.status}"
                )
            else:
                state.set_evaluation_result("stability", self._create_error_result(
                    "stability_risk_evaluator", str(stability_result)
                ))
            
            await asyncio.sleep(2)  # –ü–∞—É–∑–∞
            
        except Exception as e:
            self.graph_logger.log_workflow_step(
                assessment_id, "batch_2_error", f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–∞ 2: {e}"
            )
            
            state.set_evaluation_result("security", self._create_error_result(
                "security_risk_evaluator", f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–∞: {e}"
            ))
            state.set_evaluation_result("stability", self._create_error_result(
                "stability_risk_evaluator", f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–∞: {e}"
            ))
        
        state["current_step"] = "batch_3_evaluation"
        return state

    @log_graph_node("batch_3_evaluation")
    async def _batch_3_evaluation_node(self, state: WorkflowState) -> WorkflowState:
        """–ë–∞—Ç—á 3: –ê–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å –∏ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ —Ä–∏—Å–∫–∏ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)"""
        
        assessment_id = state["assessment_id"]
        agent_profile = state.get("agent_profile", {})
        
        self.graph_logger.log_workflow_step(
            assessment_id, 
            "batch_3_evaluation", 
            "–ó–∞–ø—É—Å–∫ –ë–∞—Ç—á–∞ 3: –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å + —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ —Ä–∏—Å–∫–∏"
        )
        
        input_data = {"agent_profile": agent_profile}
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º 2 –∞–≥–µ–Ω—Ç–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            autonomy_task = self.evaluators[RiskType.AUTONOMY].run(input_data, assessment_id)
            regulatory_task = self.evaluators[RiskType.REGULATORY].run(input_data, assessment_id)
            
            autonomy_result, regulatory_result = await asyncio.gather(
                autonomy_task, regulatory_task, return_exceptions=True
            )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if not isinstance(autonomy_result, Exception):
                state.set_evaluation_result("autonomy", autonomy_result)
                self.graph_logger.log_workflow_step(
                    assessment_id, "batch_3_autonomy",
                    f"–ê–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å: {autonomy_result.status}"
                )
            else:
                state.set_evaluation_result("autonomy", self._create_error_result(
                    "autonomy_risk_evaluator", str(autonomy_result)
                ))
            
            if not isinstance(regulatory_result, Exception):
                state.set_evaluation_result("regulatory", regulatory_result)
                self.graph_logger.log_workflow_step(
                    assessment_id, "batch_3_regulatory",
                    f"–†–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ: {regulatory_result.status}"
                )
            else:
                state.set_evaluation_result("regulatory", self._create_error_result(
                    "regulatory_risk_evaluator", str(regulatory_result)
                ))
            
            await asyncio.sleep(2)  # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞
            
        except Exception as e:
            self.graph_logger.log_workflow_step(
                assessment_id, "batch_3_error", f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–∞ 3: {e}"
            )
            
            state.set_evaluation_result("autonomy", self._create_error_result(
                "autonomy_risk_evaluator", f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–∞: {e}"
            ))
            state.set_evaluation_result("regulatory", self._create_error_result(
                "regulatory_risk_evaluator", f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–∞: {e}"
            ))
        
        state["current_step"] = "evaluation_collection"
        
        self.graph_logger.log_workflow_step(
        assessment_id, "batch_3_completed", 
        f"–ë–∞—Ç—á 3 –∑–∞–≤–µ—Ä—à–µ–Ω, –ø–µ—Ä–µ—Ö–æ–¥ –∫: {state.get('current_step', 'unknown')}"
        )
        return state

    # ===============================
    # –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´
    # ===============================

    def _create_error_result(self, agent_name: str, error_message: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—à–∏–±–∫–∏"""
        return {
            "status": "failed",
            "result_data": None,
            "agent_name": agent_name,
            "error_message": error_message,
            "execution_time_seconds": 0.0,
            "start_time": datetime.now(),
            "end_time": datetime.now()
        }

    @log_graph_node("evaluation_collection")
    async def _evaluation_collection_node(self, state: WorkflowState) -> WorkflowState:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Å–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏"""
        assessment_id = state["assessment_id"]
        # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –î–û –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.graph_logger.log_workflow_step(
            assessment_id, "evaluation_collection_start",
            f"–ù–∞—á–∞–ª–æ —Å–±–æ—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, current_step: {state.get('current_step')}"
        )
        # –ü–æ–ª—É—á–∞–µ–º —Å–≤–æ–¥–∫—É –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –æ—Ü–µ–Ω–∫–∏
        evaluation_summary = state.get_evaluation_summary()
        
        self.graph_logger.log_workflow_step(
            assessment_id,
            "evaluation_collection",
            f"–°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {evaluation_summary['successful_evaluations']}/{evaluation_summary['total_evaluations']} —É—Å–ø–µ—à–Ω–æ"
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        successful_evaluations = state.get_successful_evaluations()
        failed_evaluations = state.get_failed_evaluations()
        
        if successful_evaluations:
            self.graph_logger.log_workflow_step(
                assessment_id, 
                "successful_evaluations",
                f"–£—Å–ø–µ—à–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏: {list(successful_evaluations.keys())}"
            )
        
        if failed_evaluations:
            self.graph_logger.log_workflow_step(
                assessment_id,
                "failed_evaluations", 
                f"–ù–µ—É–¥–∞—á–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏: {list(failed_evaluations.keys())}"
            )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ 
        success_rate = evaluation_summary["success_rate"]
        if success_rate < 0.5:  # –ú–µ–Ω–µ–µ 50% —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
            state["current_step"] = "error"
            state["error_message"] = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫: {success_rate:.1%}"
            return state
        
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É
        state["current_step"] = "critic_analysis"
        
        self.graph_logger.log_workflow_step(
        assessment_id, "evaluation_collection_end",
        f"–°–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω, –ø–µ—Ä–µ—Ö–æ–¥ –∫: {state.get('current_step')}"
        )
        return state

    @log_graph_node("initialization")
    async def _initialization_node(self, state: WorkflowState) -> WorkflowState:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è workflow"""
        assessment_id = state.get("assessment_id") or f"assessment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        self.graph_logger.log_graph_start(assessment_id, "risk_assessment_workflow")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not state.get("source_files"):
            state["current_step"] = "error"
            state["error_message"] = "–ù–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã —Ñ–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
            return state
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
        state.update({
            "assessment_id": assessment_id,
            "current_step": "profiling",
            "retry_count": {},
            "max_retries": self.max_retries,
            "quality_threshold": self.quality_threshold,
            "evaluation_results": {},
            "critic_results": {},
            "start_time": datetime.now()
        })
        
        return state
    
    @log_graph_node("evaluation_preparation")
    async def _evaluation_preparation_node(self, state: WorkflowState) -> WorkflowState:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ —Ä–∏—Å–∫–æ–≤"""
        assessment_id = state["assessment_id"]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –∞–≥–µ–Ω—Ç–∞
        if not state.get("agent_profile"):
            state["current_step"] = "error"
            state["error_message"] = "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –∞–≥–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è"
            return state
        
        self.graph_logger.log_workflow_step(
            assessment_id, 
            "evaluation_preparation", 
            "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ 6 —Ç–∏–ø–æ–≤ —Ä–∏—Å–∫–æ–≤"
        )
        
        # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–∞—Ö
        state["evaluation_results"] = {}
        state["current_step"] = "parallel_evaluation"
        
        return state
    
    
    
    @log_graph_node("quality_check")
    async def _quality_check_node(self, state: WorkflowState) -> WorkflowState:
        """–ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –±–µ–∑ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫—Ä–∏—Ç–∏–∫–∞"""
        assessment_id = state["assessment_id"]
        
        self.graph_logger.log_workflow_step(
            assessment_id, "quality_check_start",
            f"–ù–∞—á–∞–ª–æ quality_check, –≤—Ö–æ–¥—è—â–∏–π current_step: {state.get('current_step')}"
        )

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏
        try:
            evaluation_results = state.get_successful_evaluations()
            self.graph_logger.log_workflow_step(
                assessment_id, "quality_check_data",
                f"–£—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫: {len(evaluation_results)}, —Ç–∏–ø—ã: {list(evaluation_results.keys())}"
            )
        except Exception as e:
            self.graph_logger.log_workflow_step(
                assessment_id, "quality_check_data_error",
                f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è successful_evaluations: {e}"
            )
            evaluation_results = {}

        # –ï—Å–ª–∏ –Ω–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫, –∏–¥–µ–º –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫
        if not evaluation_results:
            self.graph_logger.log_workflow_step(
                assessment_id, "quality_check_no_evaluations",
                "‚ùå –ù–ï–¢ –£–°–ü–ï–®–ù–´–• –û–¶–ï–ù–û–ö - —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º error"
            )
            state["current_step"] = "error"
            state["error_message"] = "–ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ —Ä–∏—Å–∫–æ–≤"
            state["retry_needed"] = []
            return state
        
        # –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Å—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        
        # 1. –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
        success_rate = len(evaluation_results) / 6  # 6 —Ç–∏–ø–æ–≤ —Ä–∏—Å–∫–æ–≤ –≤—Å–µ–≥–æ
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏–∫–∞ (–∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞)
        critic_results = state.get("critic_results", {})
        has_critic_results = bool(critic_results)
        
        self.graph_logger.log_workflow_step(
            assessment_id, "quality_check_metrics",
            f"Success rate: {success_rate:.2f}, –∏–º–µ–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏–∫–∞: {has_critic_results}"
        )
        
        if has_critic_results:
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
            retry_needed = []
            quality_scores = []
            
            for risk_type, critic_result in critic_results.items():
                try:
                    if isinstance(critic_result, dict):
                        if (critic_result.get("status") == "completed" and 
                            critic_result.get("result_data") and 
                            "critic_evaluation" in critic_result["result_data"]):
                            
                            critic_eval = critic_result["result_data"]["critic_evaluation"]
                            quality_scores.append(critic_eval.get("quality_score", 7.0))
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –ø–æ–≤—Ç–æ—Ä
                            if not critic_eval.get("is_acceptable", True):
                                retry_count = state.get("retry_count", {})
                                current_retries = retry_count.get(risk_type, 0)
                                max_retries = state.get("max_retries", 3)
                                
                                if current_retries < max_retries:
                                    retry_needed.append(risk_type)
                        else:
                            quality_scores.append(7.0)
                            
                except Exception as e:
                    self.graph_logger.log_workflow_step(
                        assessment_id, "quality_check_warning",
                        f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∫—Ä–∏—Ç–∏–∫–∞ –¥–ª—è {risk_type}: {e}"
                    )
                    quality_scores.append(7.0)
            
            avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 7.0
            
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫—Ä–∏—Ç–∏–∫–∞, –¥–µ–ª–∞–µ–º –±–∞–∑–æ–≤—É—é –æ—Ü–µ–Ω–∫—É
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: —á–µ–º –±–æ–ª—å—à–µ —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫, —Ç–µ–º –≤—ã—à–µ –∫–∞—á–µ—Å—Ç–≤–æ
            base_quality = 5.0 + (success_rate * 5.0)  # –û—Ç 5.0 –¥–æ 10.0
            avg_quality = base_quality
            retry_needed = []
            
            self.graph_logger.log_workflow_step(
                assessment_id, "quality_check_basic_assessment",
                f"–ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {avg_quality:.1f} (–Ω–∞ –æ—Å–Ω–æ–≤–µ success_rate={success_rate:.2f})"
            )
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        self.graph_logger.log_quality_check(
            assessment_id, 
            "overall", 
            avg_quality, 
            self.quality_threshold
        )
        
        # –ü—Ä–∏–Ω–∏–º–∞–µ–º —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞
        state["average_quality"] = avg_quality
        
        if retry_needed:
            # –ï—Å—Ç—å –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª –∫—Ä–∏—Ç–∏–∫)
            state["retry_needed"] = retry_needed
            state["current_step"] = "retry_needed"
            
            self.graph_logger.log_workflow_step(
                assessment_id, "quality_check_retry",
                f"‚úÖ –£–°–¢–ê–ù–û–í–õ–ï–ù current_step = 'retry_needed' –¥–ª—è: {retry_needed}"
            )
            
        elif avg_quality < self.quality_threshold and not has_critic_results:
            # –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∏–∑–∫–æ–µ –∏ –∫—Ä–∏—Ç–∏–∫ –µ—â–µ –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª—Å—è - –Ω—É–∂–µ–Ω –∫—Ä–∏—Ç–∏–∫
            state["current_step"] = "needs_critic"
            state["retry_needed"] = []
            
            self.graph_logger.log_workflow_step(
                assessment_id, "quality_check_needs_critic",
                f"‚úÖ –£–°–¢–ê–ù–û–í–õ–ï–ù current_step = 'needs_critic' (–∫–∞—á–µ—Å—Ç–≤–æ {avg_quality:.1f} < {self.quality_threshold})"
            )
            
        else:
            # –í—Å–µ —Ö–æ—Ä–æ—à–æ - —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è
            state["retry_needed"] = []
            state["current_step"] = "ready_for_finalization"
            
            self.graph_logger.log_workflow_step(
                assessment_id, "quality_check_passed",
                f"‚úÖ –£–°–¢–ê–ù–û–í–õ–ï–ù current_step = 'ready_for_finalization', —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_quality:.1f}"
            )
        
        self.graph_logger.log_workflow_step(
            assessment_id, "quality_check_end",
            f"‚úÖ Quality check –∑–∞–≤–µ—Ä—à–µ–Ω, –ò–¢–û–ì–û–í–´–ô current_step: '{state.get('current_step')}'"
        )
        
        return state
    
    @log_graph_node("retry_evaluation")
    async def _retry_evaluation_node(self, state: WorkflowState) -> WorkflowState:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å —Å–µ–ª–µ–∫—Ç–∏–≤–Ω—ã–º –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º"""
        assessment_id = state["assessment_id"]
        retry_needed = state.get("retry_needed", [])
        retry_count = state.get("retry_count", {})
        
        if not retry_needed:
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–∏—Å–∫–æ–≤ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–∞, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
            state["current_step"] = "finalization"
            return state
        
        self.graph_logger.log_workflow_step(
            assessment_id,
            "retry_evaluation",
            f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è: {retry_needed}"
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤
        for risk_type in retry_needed:
            risk_key = risk_type if isinstance(risk_type, str) else risk_type.value
            retry_count[risk_key] = retry_count.get(risk_key, 0) + 1
            
            self.graph_logger.log_retry_logic(
                assessment_id,
                f"{risk_key}_evaluator", 
                retry_count[risk_key],
                self.max_retries
            )
        
        state["retry_count"] = retry_count
        
        # –°–ï–õ–ï–ö–¢–ò–í–ù–´–ô –ü–ï–†–ï–ó–ê–ü–£–°–ö —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
        agent_profile = state.get("agent_profile", {})
        input_data = {"agent_profile": agent_profile}
        
        retry_tasks = []
        for risk_type in retry_needed:
            risk_key = risk_type if isinstance(risk_type, str) else risk_type.value
            
            # –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∏–º–µ–Ω –∫ RiskType enum
            risk_type_mapping = {
                "ethical": RiskType.ETHICAL,
                "stability": RiskType.STABILITY,
                "security": RiskType.SECURITY,
                "autonomy": RiskType.AUTONOMY,
                "regulatory": RiskType.REGULATORY,
                "social": RiskType.SOCIAL
            }
            
            risk_enum = risk_type_mapping.get(risk_key)
            if risk_enum and risk_enum in self.evaluators:
                self.graph_logger.log_workflow_step(
                    assessment_id, f"retry_{risk_key}",
                    f"–ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—É—Å–∫ –æ—Ü–µ–Ω—â–∏–∫–∞ {risk_key}"
                )
                
                task = self.evaluators[risk_enum].run(input_data, assessment_id)
                retry_tasks.append((risk_key, task))
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
        if retry_tasks:
            try:
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Å –Ω–µ–±–æ–ª—å—à–∏–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å LLM
                for i, (risk_key, task) in enumerate(retry_tasks):
                    if i > 0:
                        await asyncio.sleep(3)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    
                    try:
                        result = await task
                        state.set_evaluation_result(risk_key, result)
                        
                        self.graph_logger.log_workflow_step(
                            assessment_id, f"retry_{risk_key}_completed",
                            f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ {risk_key}: {result.status}"
                        )
                        
                    except Exception as e:
                        # –ï—Å–ª–∏ –ø–æ–≤—Ç–æ—Ä —Ç–æ–∂–µ –Ω–µ —É–¥–∞–ª—Å—è
                        error_result = self._create_error_result(
                            f"{risk_key}_risk_evaluator", 
                            f"–û—à–∏–±–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ—Ü–µ–Ω–∫–∏: {e}"
                        )
                        state.set_evaluation_result(risk_key, error_result)
                        
                        self.graph_logger.log_workflow_step(
                            assessment_id, f"retry_{risk_key}_failed",
                            f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ {risk_key} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}"
                        )
            
            except Exception as e:
                self.graph_logger.log_workflow_step(
                    assessment_id, "retry_critical_error",
                    f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –æ—Ü–µ–Ω–∫–∞—Ö: {e}"
                )
        
        # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ–≤—Ç–æ—Ä–æ–≤ –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –æ–±—Ä–∞—Ç–Ω–æ –∫ –∫—Ä–∏—Ç–∏–∫—É
        state["retry_needed"] = []
        state["current_step"] = "critic_analysis"
        
        return state
    
    @log_graph_node("finalization")
    async def _finalization_node(self, state: WorkflowState) -> WorkflowState:
        """–ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è —Å —Ä–µ—à–µ–Ω–∏–µ–º –æ—à–∏–±–∫–∏ result_data"""
        assessment_id = state["assessment_id"]
        
        self.graph_logger.log_workflow_step(
        assessment_id, "finalization_entry",
        "üéØ –£–°–ü–ï–®–ù–û –¥–æ—à–ª–∏ –¥–æ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏!"
        )

        start_time = state.get("start_time", datetime.now())
        
        try:
            # –®–∞–≥ 1: –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –∞–≥–µ–Ω—Ç–∞
            agent_profile_data = state.get("agent_profile", {})
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç AgentProfile —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫
            try:
                agent_profile = AgentProfile(**agent_profile_data)
            except Exception as e:
                self.graph_logger.log_workflow_step(
                    assessment_id, 
                    "finalization_warning", 
                    f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è AgentProfile: {e}"
                )
                # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
                agent_profile = AgentProfile(
                    name=agent_profile_data.get("name", "Unknown"),
                    description=agent_profile_data.get("description", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"),
                    agent_type=agent_profile_data.get("agent_type", "other"),
                    llm_model=agent_profile_data.get("llm_model", "unknown"),
                    autonomy_level=agent_profile_data.get("autonomy_level", "supervised"),
                    target_audience=agent_profile_data.get("target_audience", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                )
            
            # –®–∞–≥ 2: –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏
            evaluation_results = state.get_successful_evaluations()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è extract_risk_evaluations_from_results
            formatted_evaluation_results = {}
            for risk_type, result in evaluation_results.items():
                # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                if isinstance(result, dict):
                    # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ dict, —Å–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Å –Ω—É–∂–Ω—ã–º–∏ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
                    formatted_result = type('AgentTaskResult', (), {
                        'status': ProcessingStatus.COMPLETED,
                        'result_data': result.get("result_data", {}),
                        'agent_name': result.get("agent_name", "unknown")
                    })()
                    
                    # –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∏–º–µ–Ω –∫ RiskType enum
                    risk_type_mapping = {
                        "ethical": RiskType.ETHICAL,
                        "stability": RiskType.STABILITY,
                        "security": RiskType.SECURITY,
                        "autonomy": RiskType.AUTONOMY,
                        "regulatory": RiskType.REGULATORY,
                        "social": RiskType.SOCIAL
                    }
                    
                    risk_enum = risk_type_mapping.get(risk_type)
                    if risk_enum:
                        formatted_evaluation_results[risk_enum] = formatted_result
            
            # –®–∞–≥ 3: –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫
            risk_evaluations = {}
            try:
                if formatted_evaluation_results:
                    from ..agents.evaluator_agents import extract_risk_evaluations_from_results
                    risk_evaluations = extract_risk_evaluations_from_results(formatted_evaluation_results)
            except Exception as e:
                self.graph_logger.log_workflow_step(
                    assessment_id,
                    "finalization_warning", 
                    f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ü–µ–Ω–æ–∫ —Ä–∏—Å–∫–æ–≤: {e}"
                )
                # –°–æ–∑–¥–∞–µ–º fallback –æ—Ü–µ–Ω–∫–∏ –∏–∑ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                risk_evaluations = self._create_fallback_risk_evaluations(evaluation_results)
            
            # –®–∞–≥ 4: –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫
            if risk_evaluations:
                try:
                    from ..agents.evaluator_agents import calculate_overall_risk_score, get_highest_risk_areas
                    overall_score, overall_level = calculate_overall_risk_score(risk_evaluations)
                    highest_risk_areas = get_highest_risk_areas(risk_evaluations, threshold=10)
                except Exception as e:
                    self.graph_logger.log_workflow_step(
                        assessment_id,
                        "finalization_warning",
                        f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫: {e}"
                    )
                    # Fallback —Ä–∞—Å—á–µ—Ç
                    overall_score, overall_level = self._calculate_fallback_metrics(evaluation_results)
                    highest_risk_areas = []
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –æ—Ü–µ–Ω–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                overall_score, overall_level = 6, "low" 
                highest_risk_areas = []
            
            # –®–∞–≥ 5: –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            all_recommendations = []
            for risk_eval in risk_evaluations.values():
                if hasattr(risk_eval, 'recommendations') and risk_eval.recommendations:
                    all_recommendations.extend(risk_eval.recommendations)
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–∑ –æ—Ü–µ–Ω–æ–∫, –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if not all_recommendations:
                all_recommendations = self._extract_recommendations_from_raw_results(evaluation_results)
            
            # –î–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ–º –∏ –±–µ—Ä–µ–º —Ç–æ–ø —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            unique_recommendations = list(dict.fromkeys(all_recommendations))[:10]
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, –¥–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—ã–µ
            if not unique_recommendations:
                unique_recommendations = [
                    "–†–µ–≥—É–ª—è—Ä–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞",
                    "–û–±–µ—Å–ø–µ—á–∏—Ç—å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π –Ω–∞–¥–∑–æ—Ä –∑–∞ –ø—Ä–∏–Ω—è—Ç–∏–µ–º —Ä–µ—à–µ–Ω–∏–π",
                    "–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏",
                    "–ü—Ä–æ–≤–æ–¥–∏—Ç—å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤",
                    "–í–Ω–µ–¥—Ä–∏—Ç—å —Å–∏—Å—Ç–µ–º—É –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö –¥–µ–π—Å—Ç–≤–∏–π –∞–≥–µ–Ω—Ç–∞"
                ]
            
            # –®–∞–≥ 6: –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é –æ—Ü–µ–Ω–∫—É
            processing_time = (datetime.now() - start_time).total_seconds()
            
            final_assessment_data = {
                "agent_profile": agent_profile.dict() if hasattr(agent_profile, 'dict') else agent_profile_data,
                "assessment_id": assessment_id,
                "risk_evaluations": {
                    str(k.value if hasattr(k, 'value') else k): v.dict() if hasattr(v, 'dict') else v 
                    for k, v in risk_evaluations.items()
                },
                "overall_risk_score": overall_score,
                "overall_risk_level": overall_level,
                "highest_risk_areas": [
                    str(area.value if hasattr(area, 'value') else area) 
                    for area in highest_risk_areas
                ],
                "priority_recommendations": unique_recommendations,
                "suggested_guardrails": self._generate_guardrails(overall_level, highest_risk_areas),
                "processing_time_seconds": processing_time,
                "quality_checks_passed": len(state.get("retry_needed", [])) == 0,
                "evaluation_summary": state.get_evaluation_summary()
            }
            
            # –®–∞–≥ 7: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö (—Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫)
            try:
                db_manager = await get_db_manager()
                profile_id = await db_manager.save_agent_profile(agent_profile)
                saved_assessment_id = assessment_id
            except Exception as e:
                self.graph_logger.log_workflow_step(
                    assessment_id,
                    "finalization_warning",
                    f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}"
                )
                profile_id = None
                saved_assessment_id = assessment_id
            
            # –®–∞–≥ 8: –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            state.update({
                "final_assessment": final_assessment_data,
                "saved_assessment_id": saved_assessment_id,
                "profile_id": profile_id,
                "current_step": "completed",
                "processing_time": processing_time
            })
            
            # –®–∞–≥ 9: –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
            successful_evaluations = len(evaluation_results)
            total_possible = 6  # 6 —Ç–∏–ø–æ–≤ —Ä–∏—Å–∫–æ–≤
            
            self.graph_logger.log_graph_completion(
                assessment_id, 
                processing_time, 
                successful_evaluations
            )
            
            self.graph_logger.log_workflow_step(
                assessment_id,
                "finalization_success",
                f"–§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful_evaluations}/{total_possible} –æ—Ü–µ–Ω–æ–∫, "
                f"–æ–±—â–∏–π —Ä–∏—Å–∫: {overall_level} ({overall_score}), –≤—Ä–µ–º—è: {processing_time:.2f}—Å"
            )
            
            return state
            
        except Exception as e:
            # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
            self.graph_logger.log_workflow_step(
                assessment_id,
                "finalization_critical_error",
                f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏: {e}"
            )
            
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            fallback_assessment = {
                "assessment_id": assessment_id,
                "overall_risk_score": 12,
                "overall_risk_level": "medium",
                "priority_recommendations": [
                    "–ü—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–æ–≤",
                    "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
                    "–û–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ò–ò"
                ],
                "error_message": f"–û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}",
                "processing_time_seconds": (datetime.now() - start_time).total_seconds()
            }
            
            state.update({
                "final_assessment": fallback_assessment,
                "current_step": "error",
                "error_message": f"–û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}"
            })
            
            return state
    
    # ===============================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ –î–õ–Ø –§–ò–ù–ê–õ–ò–ó–ê–¶–ò–ò
# ===============================

    def _create_fallback_risk_evaluations(self, evaluation_results: Dict[str, Any]) -> Dict[Any, Any]:
        """–°–æ–∑–¥–∞–µ—Ç fallback –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –∏–∑ —Å—ã—Ä—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        from ..models.risk_models import RiskEvaluation, RiskType
        
        fallback_evaluations = {}
        
        risk_type_mapping = {
            "ethical": RiskType.ETHICAL,
            "stability": RiskType.STABILITY,
            "security": RiskType.SECURITY,
            "autonomy": RiskType.AUTONOMY,
            "regulatory": RiskType.REGULATORY,
            "social": RiskType.SOCIAL
        }
        
        for risk_type_str, result in evaluation_results.items():
            risk_type_enum = risk_type_mapping.get(risk_type_str)
            if risk_type_enum:
                try:
                    result_data = result.get("result_data", {})
                    risk_eval_data = result_data.get("risk_evaluation", {})
                    
                    if risk_eval_data:
                        # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å RiskEvaluation –∏–∑ –¥–∞–Ω–Ω—ã—Ö
                        risk_evaluation = RiskEvaluation(
                            risk_type=risk_type_enum,
                            evaluator_agent=result.get("agent_name", "unknown"),
                            probability_score=risk_eval_data.get("probability_score", 3),
                            impact_score=risk_eval_data.get("impact_score", 3),
                            probability_reasoning=risk_eval_data.get("probability_reasoning", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"),
                            impact_reasoning=risk_eval_data.get("impact_reasoning", "–ù–µ —É–∫–∞–∑–∞–Ω–æ"),
                            recommendations=risk_eval_data.get("recommendations", []),
                            confidence_level=risk_eval_data.get("confidence_level", 0.7)
                        )
                        fallback_evaluations[risk_type_enum] = risk_evaluation
                except Exception:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å, —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É
                    fallback_evaluations[risk_type_enum] = RiskEvaluation(
                        risk_type=risk_type_enum,
                        evaluator_agent="fallback",
                        probability_score=3,
                        impact_score=3,
                        probability_reasoning="Fallback –æ—Ü–µ–Ω–∫–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞",
                        impact_reasoning="Fallback –æ—Ü–µ–Ω–∫–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞",
                        recommendations=["–ü—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É"],
                        confidence_level=0.3
                    )
        
        return fallback_evaluations

    def _calculate_fallback_metrics(self, evaluation_results: Dict[str, Any]) -> tuple[int, str]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç fallback –º–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞"""
        
        if not evaluation_results:
            return 6, "low"
        
        try:
            total_scores = []
            for result in evaluation_results.values():
                result_data = result.get("result_data", {})
                risk_eval = result_data.get("risk_evaluation", {})
                total_score = risk_eval.get("total_score")
                
                if total_score and isinstance(total_score, (int, float)):
                    total_scores.append(int(total_score))
            
            if total_scores:
                avg_score = sum(total_scores) // len(total_scores)
                max_score = max(total_scores)
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è
                if max_score <= 6:
                    return max_score, "low"
                elif max_score <= 14:
                    return max_score, "medium"
                else:
                    return max_score, "high"
            
        except Exception:
            pass
        
        # Fallback - —Å—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫
        return 9, "medium"

    def _extract_recommendations_from_raw_results(self, evaluation_results: Dict[str, Any]) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑ —Å—ã—Ä—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏"""
        
        recommendations = []
        
        for result in evaluation_results.values():
            try:
                result_data = result.get("result_data", {})
                risk_eval = result_data.get("risk_evaluation", {})
                risk_recommendations = risk_eval.get("recommendations", [])
                
                if isinstance(risk_recommendations, list):
                    recommendations.extend(risk_recommendations)
            except Exception:
                continue
        
        return recommendations

    def _generate_guardrails(self, risk_level: str, highest_risk_areas: List[Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∑–∞—â–∏—Ç–Ω—ã–º –º–µ—Ä–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞"""
        
        base_guardrails = [
            "–í–Ω–µ–¥—Ä–∏—Ç—å —Å–∏—Å—Ç–µ–º—É –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö –¥–µ–π—Å—Ç–≤–∏–π –∞–≥–µ–Ω—Ç–∞",
            "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–Ω–æ–º–∞–ª—å–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è",
            "–û–±–µ—Å–ø–µ—á–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"
        ]
        
        if risk_level == "high":
            base_guardrails.extend([
                "–¢—Ä–µ–±–æ–≤–∞—Ç—å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ—à–µ–Ω–∏–π",
                "–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º",
                "–ü—Ä–æ–≤–æ–¥–∏—Ç—å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –∞—É–¥–∏—Ç –¥–µ–π—Å—Ç–≤–∏–π –∞–≥–µ–Ω—Ç–∞",
                "–í–Ω–µ–¥—Ä–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –∞–Ω–æ–º–∞–ª–∏—è—Ö"
            ])
        elif risk_level == "medium":
            base_guardrails.extend([
                "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏",
                "–ü—Ä–æ–≤–æ–¥–∏—Ç—å –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥",
                "–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∞–≥–µ–Ω—Ç–∞"
            ])
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±–ª–∞—Å—Ç–µ–π –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞
        for risk_area in highest_risk_areas:
            area_str = str(risk_area.value if hasattr(risk_area, 'value') else risk_area)
            
            if area_str == "ethical":
                base_guardrails.append("–í–Ω–µ–¥—Ä–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
            elif area_str == "security":
                base_guardrails.append("–£—Å–∏–ª–∏—Ç—å –º–µ—Ä—ã –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
            elif area_str == "autonomy":
                base_guardrails.append("–°–Ω–∏–∑–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞")
        
        return list(dict.fromkeys(base_guardrails))  # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã

    @log_graph_node("error_handling")
    async def _error_handling_node(self, state: WorkflowState) -> WorkflowState:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫"""
        assessment_id = state["assessment_id"]

        self.graph_logger.log_workflow_step(
        assessment_id, "error_handling_entry",
        f"‚ùå –ü–æ–ø–∞–ª–∏ –≤ error_handling, –ø—Ä–∏—á–∏–Ω–∞: {state.get('error_message', 'unknown')}"
        )

        error_message = state.get("error_message", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
        
        self.graph_logger.log_workflow_step(
            assessment_id,
            "error_handling",
            f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏: {error_message}"
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        try:
            db_manager = await get_db_manager()
            await db_manager.log_processing_step(
                assessment_id=assessment_id,
                agent_name="workflow",
                task_type="error_handling",
                status=ProcessingStatus.FAILED,
                error_message=error_message
            )
        except Exception:
            pass  # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å
        
        state["current_step"] = "failed"
        return state
    
    # ===============================
    # –£—Å–ª–æ–≤–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã
    # ===============================
    
    @log_conditional_edge_func("quality_check_router") 
    def _quality_check_router(self, state: WorkflowState) -> Literal["retry", "finalize", "error", "critic"]:
        """–ü–†–ê–í–ò–õ–¨–ù–ê–Ø –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —Å —Å–µ–ª–µ–∫—Ç–∏–≤–Ω—ã–º –∫—Ä–∏—Ç–∏–∫–æ–º"""
        assessment_id = state.get("assessment_id", "unknown")

        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        current_step = state.get("current_step", "unknown")
        error_message = state.get("error_message")
        retry_needed = state.get("retry_needed", [])
        average_quality = state.get("average_quality", 7.0)
        
        self.graph_logger.log_workflow_step(
            assessment_id, 
            "router_input_analysis",
            f"Router –ø–æ–ª—É—á–∏–ª: current_step='{current_step}', error='{error_message}', retry_needed={len(retry_needed)}, avg_quality={average_quality}"
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
        try:
            evaluation_results = state.get_successful_evaluations()
            self.graph_logger.log_workflow_step(
                assessment_id, 
                "router_data_check",
                f"Router –≤–∏–¥–∏—Ç {len(evaluation_results)} —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫"
            )
        except Exception as e:
            self.graph_logger.log_workflow_step(
                assessment_id, 
                "router_data_error",
                f"Router –Ω–µ –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ: {e}"
            )
        
        # –ü—Ä–∏–Ω–∏–º–∞–µ–º —Ä–µ—à–µ–Ω–∏–µ –æ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏
        if error_message or current_step == "error":
            # –ï—Å—Ç—å –æ—à–∏–±–∫–∞ - –∏–¥–µ–º –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫
            self.graph_logger.log_workflow_step(
                assessment_id, 
                "router_decision", 
                f"–†–µ—à–µ–Ω–∏–µ: ERROR (error_message='{error_message}', current_step='{current_step}')"
            )
            return "error"
            
        elif current_step == "retry_needed" and retry_needed:
            # –ù—É–∂–Ω—ã –ø–æ–≤—Ç–æ—Ä—ã - –∏–¥–µ–º –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É
            self.graph_logger.log_workflow_step(
                assessment_id, 
                "router_decision", 
                f"–†–µ—à–µ–Ω–∏–µ: RETRY (retry_needed={retry_needed})"
            )
            return "retry"
            
        elif current_step == "ready_for_finalization":
            # –í—Å–µ –≥–æ—Ç–æ–≤–æ –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
            self.graph_logger.log_workflow_step(
                assessment_id, 
                "router_decision", 
                f"–†–µ—à–µ–Ω–∏–µ: FINALIZE (all good, quality={average_quality})"
            )
            return "finalize"
            
        elif current_step == "needs_critic" or average_quality < self.quality_threshold:
            # –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∏–∑–∫–æ–µ - –Ω—É–∂–µ–Ω –∫—Ä–∏—Ç–∏–∫
            self.graph_logger.log_workflow_step(
                assessment_id, 
                "router_decision", 
                f"–†–µ—à–µ–Ω–∏–µ: CRITIC (–Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ {average_quality} < {self.quality_threshold})"
            )
            return "critic"
            
        else:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è
            self.graph_logger.log_workflow_step(
                assessment_id, 
                "router_decision", 
                f"–†–µ—à–µ–Ω–∏–µ: FINALIZE (fallback, —Å–æ—Å—Ç–æ—è–Ω–∏–µ '{current_step}')"
            )
            return "finalize"
    
    # ===============================
    # –ü—É–±–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    # ===============================
    
    async def run_assessment(
        self,
        source_files: List[str],
        agent_name: Optional[str] = None,
        assessment_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–∞
        
        Args:
            source_files: –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤/–ø–∞–ø–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            agent_name: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∏–º—è –∞–≥–µ–Ω—Ç–∞
            assessment_id: ID –æ—Ü–µ–Ω–∫–∏ (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω)
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤
        """
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        initial_state = WorkflowState(
            source_files=source_files,
            preliminary_agent_name=agent_name or "Unknown_Agent",
            assessment_id=assessment_id
        )
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≥—Ä–∞—Ñ
        try:
            final_state = await self.graph.ainvoke(initial_state.dict())
            
            return {
                "success": True,
                "assessment_id": final_state.get("assessment_id"),
                "final_assessment": final_state.get("final_assessment"),
                "processing_time": final_state.get("processing_time"),
                "current_step": final_state.get("current_step"),
                "saved_assessment_id": final_state.get("saved_assessment_id")
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "assessment_id": initial_state.assessment_id
            }
    
    async def get_assessment_status(self, assessment_id: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ—Ü–µ–Ω–∫–∏"""
        try:
            db_manager = await get_db_manager()
            logs = await db_manager.get_processing_logs(assessment_id)
            
            return {
                "assessment_id": assessment_id,
                "logs": logs,
                "total_steps": len(logs)
            }
        except Exception as e:
            return {
                "assessment_id": assessment_id,
                "error": str(e)
            }
    
    def get_graph_visualization(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞"""
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –≥—Ä–∞—Ñ–∞
        return "–ì—Ä–∞—Ñ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤ (–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)"


# ===============================
# –§–∞–±—Ä–∏–∫–∏ –∏ —É—Ç–∏–ª–∏—Ç—ã
# ===============================

def create_risk_assessment_workflow(
    llm_base_url: str = "http://127.0.0.1:1234",
    llm_model: str = "qwen3-4b",
    quality_threshold: float = 7.0,
    max_retries: int = 3
) -> RiskAssessmentWorkflow:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ workflow –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤
    
    Args:
        llm_base_url: URL LLM —Å–µ—Ä–≤–µ—Ä–∞
        llm_model: –ú–æ–¥–µ–ª—å LLM
        quality_threshold: –ü–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∞
        max_retries: –ú–∞–∫—Å–∏–º—É–º –ø–æ–≤—Ç–æ—Ä–æ–≤
        
    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π workflow
    """
    return RiskAssessmentWorkflow(
        llm_base_url=llm_base_url,
        llm_model=llm_model,
        quality_threshold=quality_threshold,
        max_retries=max_retries
    )


def create_workflow_from_env() -> RiskAssessmentWorkflow:
    """–°–æ–∑–¥–∞–Ω–∏–µ workflow –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    import os
    
    return create_risk_assessment_workflow(
        llm_base_url=os.getenv("LLM_BASE_URL", "http://127.0.0.1:1234"),
        llm_model=os.getenv("LLM_MODEL", "qwen3-4b"),
        quality_threshold=float(os.getenv("QUALITY_THRESHOLD", "7.0")),
        max_retries=int(os.getenv("MAX_RETRY_COUNT", "3"))
    )


# –≠–∫—Å–ø–æ—Ä—Ç
__all__ = [
    "RiskAssessmentWorkflow",
    "create_risk_assessment_workflow", 
    "create_workflow_from_env"
]