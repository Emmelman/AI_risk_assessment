# src/agents/base_agent.py
"""
–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤
–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±—â–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤

–û–ë–ù–û–í–õ–ï–ù–û: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–º LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä–æ–º
"""

import asyncio
import json
import re
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List, Union
from datetime import datetime
from dataclasses import dataclass

from ..utils.llm_client import LLMClient, LLMConfig, LLMMessage, RiskAnalysisLLMClient
from ..utils.logger import get_logger, log_agent_execution, log_llm_call
from ..models.risk_models import AgentTaskResult, ProcessingStatus
from ..config import get_global_llm_config


@dataclass
class AgentConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –±–µ–∑ LLM –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)"""
    name: str
    description: str
    max_retries: int = 3
    timeout_seconds: int = 180
    use_risk_analysis_client: bool = False
    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è LLM –Ω–∞—Å—Ç—Ä–æ–µ–∫ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    llm_override: Optional[LLMConfig] = None


class BaseAgent(ABC):
    """
    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤
    
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç:
    - –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ LLM —á–µ—Ä–µ–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä
    - –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    - –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –ø–æ–≤—Ç–æ—Ä—ã
    - –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤
    """
    
    def __init__(self, config: AgentConfig):
        self.config = config
        self.logger = get_logger()
        
        # –ü–æ–ª—É—á–∞–µ–º LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
        self._setup_llm_client()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_execution_time": 0.0,
            "average_response_time": 0.0
        }
    
    def _setup_llm_client(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM –∫–ª–∏–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä"""
        if self.config.llm_override:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
            llm_config = self.config.llm_override
        else:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
            global_config_manager = get_global_llm_config()
            unified_config = global_config_manager.get_config()
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ LLMConfig
            llm_config = LLMConfig(
                base_url=unified_config.base_url,
                model=unified_config.model,
                temperature=unified_config.temperature,
                max_tokens=unified_config.max_tokens,
                timeout=unified_config.timeout,
                max_retries=unified_config.max_retries,
                retry_delay=unified_config.retry_delay
            )
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∫–ª–∏–µ–Ω—Ç
        if self.config.use_risk_analysis_client:
            self.llm_client = RiskAnalysisLLMClient(llm_config)
        else:
            self.llm_client = LLMClient(llm_config)
    
    @property
    def name(self) -> str:
        """–ò–º—è –∞–≥–µ–Ω—Ç–∞"""
        return self.config.name
    
    @property
    def description(self) -> str:
        """–û–ø–∏—Å–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞"""
        return self.config.description
    
    @abstractmethod
    async def process(
        self, 
        input_data: Dict[str, Any], 
        assessment_id: str = "unknown"
    ) -> AgentTaskResult:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–º
        
        Args:
            input_data: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            assessment_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ—Ü–µ–Ω–∫–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
        """
        pass
    
    @abstractmethod
    def get_system_prompt(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–≥–µ–Ω—Ç–∞"""
        pass
    
    async def execute_with_retry(
        self,
        task_func,
        *args,
        max_retries: Optional[int] = None,
        **kwargs
    ) -> Any:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
        
        Args:
            task_func: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤
            *args, **kwargs: –ê—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏
        """
        retries = max_retries or self.config.max_retries
        last_error = None
        
        for attempt in range(retries + 1):
            try:
                result = await task_func(*args, **kwargs)
                
                if attempt > 0:
                    self.logger.info(f"–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ —Å –ø–æ–ø—ã—Ç–∫–∏ {attempt + 1}")
                
                return result
                
            except Exception as e:
                last_error = e
                self.logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ—É–¥–∞—á–Ω–∞: {str(e)}")
                
                if attempt < retries:
                    await asyncio.sleep(2 ** attempt)  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                else:
                    self.logger.error(f"–í—Å–µ {retries + 1} –ø–æ–ø—ã—Ç–æ–∫ –Ω–µ—É–¥–∞—á–Ω—ã. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        
        raise last_error
    
    async def call_llm(
        self,
        prompt: str,
        context: str = "",
        assessment_id: str = "unknown",
        temperature: Optional[float] = None
    ) -> str:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã–∑–æ–≤–∞ LLM
        
        Args:
            prompt: –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            assessment_id: ID –æ—Ü–µ–Ω–∫–∏
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏)
            
        Returns:
            –û—Ç–≤–µ—Ç –æ—Ç LLM
        """
        system_prompt = self.get_system_prompt()
        
        messages = [
            LLMMessage(role="system", content=system_prompt),
            LLMMessage(role="user", content=f"{context}\n\n{prompt}")
        ]
        
        response = await self.llm_client.chat(
            messages=messages,
            temperature=temperature or self.llm_client.config.temperature
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–∑–æ–≤ LLM
        self.logger.log_llm_request(
            self.name,
            assessment_id,
            response.model,
            response.usage.get("total_tokens", 0)
        )
        
        return response.content
    
    async def call_llm_structured(
        self,
        data_to_analyze: str,
        extraction_prompt: str,
        assessment_id: str = "unknown",
        expected_format: str = "JSON"
    ) -> Dict[str, Any]:
        """
        –í—ã–∑–æ–≤ LLM –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            data_to_analyze: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            extraction_prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            assessment_id: ID –æ—Ü–µ–Ω–∫–∏
            expected_format: –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞
            
        Returns:
            –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        if not isinstance(self.llm_client, (LLMClient, RiskAnalysisLLMClient)):
            raise ValueError("LLM –∫–ª–∏–µ–Ω—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã")
        
        result = await self.llm_client.extract_structured_data(
            data_to_analyze=data_to_analyze,
            extraction_prompt=extraction_prompt,
            expected_format=expected_format
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–∑–æ–≤
        self.logger.log_llm_request(
            self.name,
            assessment_id,
            self.llm_client.config.model,
            0  # –¢–æ–∫–µ–Ω—ã —É–∂–µ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω—ã –≤–Ω—É—Ç—Ä–∏ extract_structured_data
        )
        
        return result
    
    def validate_result(self, result_data: Dict[str, Any]) -> bool:
        """
        –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–≥–µ–Ω—Ç–∞
        –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        
        Args:
            result_data: –î–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            
        Returns:
            True –µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–µ–Ω
        """
        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if not isinstance(result_data, dict):
            return False
        
        return True
    
    def _get_required_result_fields(self) -> List[str]:
        """–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞"""
        return [
            "probability_score", "impact_score", "total_score", 
            "risk_level", "probability_reasoning", "impact_reasoning"
        ]
    
    def _parse_llm_response(self, response_content: str) -> Dict[str, Any]:
        """–ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ LLM —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å—é"""
        
        try:
            # –®–∞–≥ 1: –û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            cleaned_content = response_content.strip()
            
            # –£–¥–∞–ª—è–µ–º —Ç–µ–≥–∏ <think>...</think> –µ—Å–ª–∏ –µ—Å—Ç—å
            import re
            cleaned_content = re.sub(r'<think>.*?</think>', '', cleaned_content, flags=re.DOTALL)
            cleaned_content = cleaned_content.strip()
            
            # –£–¥–∞–ª—è–µ–º markdown –±–ª–æ–∫–∏
            if "```json" in cleaned_content:
                # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ JSON –±–ª–æ–∫–∏
                json_blocks = re.findall(r'```json\s*(.*?)\s*```', cleaned_content, re.DOTALL)
                if json_blocks:
                    json_content = json_blocks[-1].strip()  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫
                else:
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥, –±–µ—Ä–µ–º –≤—Å–µ –ø–æ—Å–ª–µ ```json
                    start = cleaned_content.find("```json") + 7
                    json_content = cleaned_content[start:].strip()
            else:
                # –ò—â–µ–º JSON –ø–æ —Ñ–∏–≥—É—Ä–Ω—ã–º —Å–∫–æ–±–∫–∞–º
                json_match = re.search(r'\{.*\}', cleaned_content, re.DOTALL)
                if json_match:
                    json_content = json_match.group().strip()
                else:
                    json_content = cleaned_content
            
            # –®–∞–≥ 2: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ JSON
            # –£–±–∏—Ä–∞–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ü–µ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –ø–æ—Å–ª–µ }
            if '}' in json_content:
                end_pos = json_content.rfind('}')
                json_content = json_content[:end_pos + 1]
            
            # –®–∞–≥ 3: –ü—ã—Ç–∞–µ–º—Å—è –ø–∞—Ä—Å–∏—Ç—å JSON
            try:
                parsed_data = json.loads(json_content)
            except json.JSONDecodeError:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ—á–∏–Ω–∏—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ JSON
                json_content = self._fix_common_json_errors(json_content)
                parsed_data = json.loads(json_content)
            
            # –®–∞–≥ 4: –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï - –≤—Å–µ–≥–¥–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
            parsed_data = self._ensure_required_fields(parsed_data)
            
            return parsed_data
            
        except Exception as e:
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–æ–≥–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            self.logger.warning(
                f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ LLM –æ—Ç–≤–µ—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback: {e}"
            )
            self.logger.debug(
                f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {response_content[:200]}..."
            )
            return self._get_default_evaluation_data(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}")

    def _fix_common_json_errors(self, json_content: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ JSON –æ—Ç LLM"""
        
        # –£–±–∏—Ä–∞–µ–º trailing commas
        json_content = re.sub(r',\s*}', '}', json_content)
        json_content = re.sub(r',\s*]', ']', json_content)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∞—Ö
        # –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –¥–æ—Ä–∞–±–æ—Ç–∫–∏
        json_content = re.sub(r'(?<!\\)"(?=[^,}\]]*[,}\]])', '\\"', json_content)
        
        # –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ JSON (–µ—Å–ª–∏ –µ—Å—Ç—å)
        json_content = re.sub(r'//.*?\n', '\n', json_content)
        json_content = re.sub(r'/\*.*?\*/', '', json_content, flags=re.DOTALL)
        
        return json_content

    def _ensure_required_fields(self, parsed_data: Dict[str, Any]) -> Dict[str, Any]:
        """–£–õ–£–ß–®–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π"""
        
        # –®–∞–≥ 1: –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è —Å —É–º–Ω—ã–º–∏ –¥–µ—Ñ–æ–ª—Ç–∞–º–∏
        required_fields = {
            "probability_score": 3,
            "impact_score": 3, 
            "total_score": 9,
            "risk_level": "medium",
            "probability_reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ LLM",
            "impact_reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ LLM",
            "key_factors": [],
            "recommendations": [],
            "confidence_level": 0.7
        }
        
        # –®–∞–≥ 2: –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è
        for field, default_value in required_fields.items():
            if field not in parsed_data or parsed_data[field] is None:
                parsed_data[field] = default_value
                self.logger.debug(
                    f"üîß –î–æ–±–∞–≤–ª–µ–Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–µ –ø–æ–ª–µ {field}: {default_value}"
                )
        
        # –®–∞–≥ 3: –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        parsed_data = self._validate_and_fix_field_types(parsed_data)
        
        # –®–∞–≥ 4: –í–∞–ª–∏–¥–∏—Ä—É–µ–º –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É
        parsed_data = self._validate_business_logic(parsed_data)
        
        return parsed_data

    def _validate_numeric_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è"""
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è probability_score (1-5)
        try:
            data["probability_score"] = int(data["probability_score"])
            if not (1 <= data["probability_score"] <= 5):
                data["probability_score"] = 3
        except (ValueError, TypeError):
            data["probability_score"] = 3
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è impact_score (1-5)
        try:
            data["impact_score"] = int(data["impact_score"])
            if not (1 <= data["impact_score"] <= 5):
                data["impact_score"] = 3
        except (ValueError, TypeError):
            data["impact_score"] = 3
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è confidence_level (0.0-1.0)
        try:
            data["confidence_level"] = float(data["confidence_level"])
            if not (0.0 <= data["confidence_level"] <= 1.0):
                data["confidence_level"] = 0.7
        except (ValueError, TypeError):
            data["confidence_level"] = 0.7
        
        return data

    def _validate_string_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –ø–æ–ª—è"""
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è risk_level
        valid_levels = ["low", "medium", "high"]
        if data.get("risk_level") not in valid_levels:
            data["risk_level"] = "medium"
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è reasoning –ø–æ–ª–µ–π
        if not data.get("probability_reasoning") or len(str(data["probability_reasoning"]).strip()) < 10:
            data["probability_reasoning"] = "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"
        
        if not data.get("impact_reasoning") or len(str(data["impact_reasoning"]).strip()) < 10:
            data["impact_reasoning"] = "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"
        
        return data

    def _validate_list_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ø–∏—Å–∫–æ–≤—ã–µ –ø–æ–ª—è"""
        
        list_fields = ["key_factors", "recommendations"]
        
        for field in list_fields:
            if not isinstance(data.get(field), list):
                data[field] = []
            
            # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ None
            data[field] = [
                item for item in data[field] 
                if item and isinstance(item, str) and item.strip()
            ]
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            data[field] = data[field][:10]
        
        return data
    
    def _validate_and_fix_field_types(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–∏–ø—ã –ø–æ–ª–µ–π"""
        
        # –ß–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è (1-5)
        score_fields = ["probability_score", "impact_score"]
        for field in score_fields:
            try:
                value = int(data[field])
                data[field] = max(1, min(5, value))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω 1-5
            except (ValueError, TypeError):
                data[field] = 3  # –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª
                self.logger.warning(
                    f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π {field}: —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ 3"
                )
        
        # Confidence level (0.0-1.0)
        try:
            value = float(data["confidence_level"])
            data["confidence_level"] = max(0.0, min(1.0, value))
        except (ValueError, TypeError):
            data["confidence_level"] = 0.7
        
        # Risk level (enum)
        valid_levels = ["low", "medium", "high"]
        if data.get("risk_level") not in valid_levels:
            data["risk_level"] = "medium"
            self.logger.warning(
                "üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π risk_level: —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ 'medium'"
            )
        
        # –°—Ç—Ä–æ–∫–æ–≤—ã–µ –ø–æ–ª—è
        string_fields = ["probability_reasoning", "impact_reasoning"]
        for field in string_fields:
            if not isinstance(data.get(field), str) or len(str(data[field]).strip()) < 5:
                data[field] = f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è {field}"
        
        # –°–ø–∏—Å–∫–æ–≤—ã–µ –ø–æ–ª—è
        list_fields = ["key_factors", "recommendations"]
        for field in list_fields:
            if not isinstance(data.get(field), list):
                data[field] = []
            else:
                # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ—Ç –ø—É—Å—Ç—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                data[field] = [
                    str(item).strip() for item in data[field] 
                    if item and str(item).strip()
                ][:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        
        return data

    def _validate_business_logic(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞"""
        
        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º total_score –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        data["total_score"] = data["probability_score"] * data["impact_score"]
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º risk_level –Ω–∞ –æ—Å–Ω–æ–≤–µ total_score
        total_score = data["total_score"]
        if total_score <= 6:
            correct_level = "low"
        elif total_score <= 14:
            correct_level = "medium"
        else:
            correct_level = "high"
        
        if data["risk_level"] != correct_level:
            old_level = data["risk_level"]
            data["risk_level"] = correct_level
            self.logger.debug(
                f"üîß –°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω risk_level: {old_level} ‚Üí {correct_level} (total_score: {total_score})"
            )
        
        return data
    
    def _get_default_evaluation_data(self, error_message: str) -> Dict[str, Any]:
        """–£–õ–£–ß–®–ï–ù–ù–´–ï –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏"""
        return {
            "probability_score": 3,
            "impact_score": 3,
            "total_score": 9,
            "risk_level": "medium",
            "probability_reasoning": f"LLM –Ω–µ —Å–º–æ–≥ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ. –û—à–∏–±–∫–∞: {error_message}",
            "impact_reasoning": f"LLM –Ω–µ —Å–º–æ–≥ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ. –û—à–∏–±–∫–∞: {error_message}",
            "key_factors": ["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"],
            "recommendations": ["–ü—Ä–æ–≤–µ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"],
            "confidence_level": 0.3  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è fallback –¥–∞–Ω–Ω—ã—Ö
        }
    
    def update_stats(self, execution_time: float, success: bool):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–≥–µ–Ω—Ç–∞"""
        self.stats["total_requests"] += 1
        self.stats["total_execution_time"] += execution_time
        
        if success:
            self.stats["successful_requests"] += 1
        else:
            self.stats["failed_requests"] += 1
        
        self.stats["average_response_time"] = (
            self.stats["total_execution_time"] / self.stats["total_requests"]
        )
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞"""
        return self.stats.copy()


class AnalysisAgent(BaseAgent):
    """
    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
    –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è –∑–∞–¥–∞—á –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    """
    
    async def analyze_data(
        self,
        data: str,
        analysis_type: str,
        assessment_id: str = "unknown"
    ) -> Dict[str, Any]:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_type: –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞
            assessment_id: ID –æ—Ü–µ–Ω–∫–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        prompt = f"–ü—Ä–æ–≤–µ–¥–∏ {analysis_type} –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
        
        return await self.call_llm_structured(
            data_to_analyze=data,
            extraction_prompt=prompt,
            assessment_id=assessment_id
        )


class EvaluationAgent(BaseAgent):
    """
    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏
    –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è –∑–∞–¥–∞—á –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤
    """
    
    def __init__(self, config: AgentConfig, risk_type: str):
        super().__init__(config)
        self.risk_type = risk_type
    
    async def evaluate_risk(
        self,
        agent_data: Dict[str, Any],
        assessment_id: str = "unknown"
    ) -> Dict[str, Any]:
        """
        –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞
        
        Args:
            agent_data: –î–∞–Ω–Ω—ã–µ –æ–± –∞–≥–µ–Ω—Ç–µ
            assessment_id: ID –æ—Ü–µ–Ω–∫–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞
        """
        evaluation_prompt = f"–û—Ü–µ–Ω–∏ {self.risk_type} —Ä–∏—Å–∫–∏ –∞–≥–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
        
        agent_data_str = json.dumps(agent_data, ensure_ascii=False, indent=2)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞
        try:
            result = await self.call_llm_structured(
                data_to_analyze=agent_data_str,
                extraction_prompt=evaluation_prompt,
                assessment_id=assessment_id
            )
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤
            result = self._ensure_required_fields(result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ {self.risk_type} —Ä–∏—Å–∫–∞: {e}")
            return self.create_fallback_result(str(e))
    
    def create_fallback_result(self, error_message: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö"""
        return self._get_default_evaluation_data(error_message)
    
    def validate_result(self, result_data: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞"""
        required_fields = self._get_required_result_fields()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        for field in required_fields:
            if field not in result_data:
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π
        try:
            prob_score = int(result_data["probability_score"])
            impact_score = int(result_data["impact_score"])
            
            if not (1 <= prob_score <= 5) or not (1 <= impact_score <= 5):
                return False
                
            if result_data["risk_level"] not in ["low", "medium", "high"]:
                return False
                
            return True
            
        except (ValueError, TypeError, KeyError):
            return False


# ===============================
# –§–∞–±—Ä–∏–∫–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ (–û–ë–ù–û–í–õ–ï–ù–ù–´–ï)
# ===============================

def create_agent_config(
    name: str,
    description: str,
    max_retries: int = 3,
    timeout_seconds: int = 120,
    use_risk_analysis_client: bool = False,
    llm_override: Optional[LLMConfig] = None
) -> AgentConfig:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞ (–Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –±–µ–∑ LLM –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
    
    Args:
        name: –ò–º—è –∞–≥–µ–Ω—Ç–∞
        description: –û–ø–∏—Å–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
        max_retries: –ú–∞–∫—Å–∏–º—É–º –ø–æ–≤—Ç–æ—Ä–æ–≤
        timeout_seconds: –¢–∞–π–º-–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        use_risk_analysis_client: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
        llm_override: –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
        
    Returns:
        –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞
    """
    return AgentConfig(
        name=name,
        description=description,
        max_retries=max_retries,
        timeout_seconds=timeout_seconds,
        use_risk_analysis_client=use_risk_analysis_client,
        llm_override=llm_override
    )


def create_default_config() -> AgentConfig:
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä)"""
    return create_agent_config(
        name="default_agent",
        description="–ê–≥–µ–Ω—Ç —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é",
        max_retries=3,
        timeout_seconds=120
    )


# –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å - —Å—Ç–∞—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å LLM –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (DEPRECATED)
def create_agent_config_legacy(
    name: str,
    description: str,
    llm_base_url: str = "http://127.0.0.1:1234",
    llm_model: str = "qwen3-4b",
    temperature: float = 0.1,
    max_retries: int = 3,
    timeout_seconds: int = 120,
    use_risk_analysis_client: bool = False
) -> AgentConfig:
    """
    DEPRECATED: –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞ (—Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    
    –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ create_agent_config() –±–µ–∑ LLM –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
    LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–µ–ø–µ—Ä—å —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ.
    """
    import warnings
    warnings.warn(
        "create_agent_config_legacy deprecated. Use create_agent_config() without LLM params.",
        DeprecationWarning,
        stacklevel=2
    )
    
    # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è/legacy –∫–æ–¥–∞
    llm_override = LLMConfig(
        base_url=llm_base_url,
        model=llm_model,
        temperature=temperature,
        timeout=timeout_seconds
    )
    
    return create_agent_config(
        name=name,
        description=description,
        max_retries=max_retries,
        timeout_seconds=timeout_seconds,
        use_risk_analysis_client=use_risk_analysis_client,
        llm_override=llm_override
    )


def create_default_config_from_env() -> AgentConfig:
    """DEPRECATED: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ create_default_config()"""
    import warnings
    warnings.warn(
        "create_default_config_from_env deprecated. Use create_default_config().",
        DeprecationWarning,
        stacklevel=2
    )
    return create_default_config()


# –≠–∫—Å–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
__all__ = [
    "BaseAgent",
    "AnalysisAgent", 
    "EvaluationAgent",
    "AgentConfig",
    "create_agent_config",
    "create_default_config",
    # Legacy exports (deprecated)
    "create_agent_config_legacy",
    "create_default_config_from_env"
]