# src/agents/critic_agent.py
"""
–ö—Ä–∏—Ç–∏–∫-–∞–≥–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–æ–≤-–æ—Ü–µ–Ω—â–∏–∫–æ–≤ —Ä–∏—Å–∫–æ–≤
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –∏ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è –æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
"""

from typing import Dict, Any, List, Optional
from datetime import datetime

from .base_agent import AnalysisAgent, AgentConfig
from ..models.risk_models import (
    RiskType, RiskEvaluation, CriticEvaluation, AgentTaskResult, ProcessingStatus
)
from ..utils.logger import LogContext


class CriticAgent(AnalysisAgent):
    """
    –ö—Ä–∏—Ç–∏–∫-–∞–≥–µ–Ω—Ç –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ü–µ–Ω–æ–∫ —Ä–∏—Å–∫–æ–≤
    
    –§—É–Ω–∫—Ü–∏–∏:
    1. –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ü–µ–Ω–æ–∫ –∞–≥–µ–Ω—Ç–æ–≤-–æ—Ü–µ–Ω—â–∏–∫–æ–≤
    2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –≤—ã–≤–æ–¥–æ–≤
    3. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
    4. –í—ã–¥–∞—á–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞
    """
    
    def __init__(self, config: AgentConfig, quality_threshold: float = 7.0):
        # –ö—Ä–∏—Ç–∏–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤
        config.use_risk_analysis_client = True
        super().__init__(config)
        
        self.quality_threshold = quality_threshold
    
    def get_system_prompt(self) -> str:
        """–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∞"""
        return f"""–¢—ã - —Å—Ç–∞—Ä—à–∏–π —ç–∫—Å–ø–µ—Ä—Ç-–∞—É–¥–∏—Ç–æ—Ä –ø–æ –æ—Ü–µ–Ω–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–æ–≤-–æ—Ü–µ–Ω—â–∏–∫–æ–≤ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤.

–ö–†–ò–¢–ï–†–ò–ò –ö–ê–ß–ï–°–¢–í–ê –û–¶–ï–ù–ö–ò:

1. –û–ë–û–°–ù–û–í–ê–ù–ù–û–°–¢–¨ (30%):
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤—ã–≤–æ–¥–æ–≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º
   - –õ–æ–≥–∏—á–Ω–æ—Å—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
   - –£—á–µ—Ç –≤—Å–µ—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤

2. –ü–û–õ–ù–û–¢–ê –ê–ù–ê–õ–ò–ó–ê (25%):
   - –†–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –≤—Å–µ—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ —Ä–∏—Å–∫–∞
   - –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
   - –£—á–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–∞–Ω–∫–æ–≤—Å–∫–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

3. –¢–û–ß–ù–û–°–¢–¨ –û–¶–ï–ù–û–ö (25%):
   - –ê–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å –±–∞–ª–ª–æ–≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∏ —Ç—è–∂–µ—Å—Ç–∏
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞
   - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –º–µ—Ç–æ–¥–∏–∫–∏

4. –ü–†–ê–ö–¢–ò–ß–ù–û–°–¢–¨ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô (20%):
   - –ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –º–µ—Ä
   - –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ—Å—Ç—å –∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è
   - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ª—É—á—à–∏–º –ø—Ä–∞–∫—Ç–∏–∫–∞–º

–®–ö–ê–õ–ê –ö–ê–ß–ï–°–¢–í–ê: 0-10 –±–∞–ª–ª–æ–≤
–ü–û–†–û–ì –ü–†–ò–ï–ú–õ–ï–ú–û–°–¢–ò: {self.quality_threshold} –±–∞–ª–ª–æ–≤

–¢–ò–ü–ò–ß–ù–´–ï –ü–†–û–ë–õ–ï–ú–´ –î–õ–Ø –í–´–Ø–í–õ–ï–ù–ò–Ø:
- –ó–∞–≤—ã—à–µ–Ω–∏–µ –∏–ª–∏ –∑–∞–Ω–∏–∂–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ –±–µ–∑ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
- –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–∂–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–∏—Å–∫–∞
- –û–±—â–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏
- –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤—ã—è–≤–ª–µ–Ω–Ω—ã–º —Ä–∏—Å–∫–∞–º
- –ù–µ—É—á–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ –±–∞–Ω–∫–æ–≤—Å–∫–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ô –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (JSON):
{{
    "quality_score": <0.0-10.0>,
    "is_acceptable": <true|false>,
    "issues_found": ["<–ø—Ä–æ–±–ª–µ–º–∞1>", "<–ø—Ä–æ–±–ª–µ–º–∞2>", ...],
    "improvement_suggestions": ["<–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ1>", "<–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ2>", ...],
    "critic_reasoning": "<–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞>"
}}

–ë—É–¥—å —Å—Ç—Ä–æ–≥–∏–º, –Ω–æ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ã–º. –í—ã—Å–æ–∫–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞ - –∑–∞–ª–æ–≥ –Ω–∞–¥–µ–∂–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤."""
    
    async def process(
        self, 
        input_data: Dict[str, Any], 
        assessment_id: str
    ) -> AgentTaskResult:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            input_data: –°–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                - risk_type: RiskType - —Ç–∏–ø —Ä–∏—Å–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                - risk_evaluation: Dict - –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏
                - agent_profile: Dict - –ø—Ä–æ—Ñ–∏–ª—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
                - evaluator_name: str - –∏–º—è –∞–≥–µ–Ω—Ç–∞-–æ—Ü–µ–Ω—â–∏–∫–∞
            assessment_id: ID –æ—Ü–µ–Ω–∫–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–æ–π
        """
        start_time = datetime.now()
        
        try:
            with LogContext("critic_analysis", assessment_id, self.name):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                risk_type = RiskType(input_data["risk_type"])
                risk_evaluation = input_data["risk_evaluation"]
                agent_profile = input_data.get("agent_profile", {})
                evaluator_name = input_data.get("evaluator_name", "unknown")
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
                critic_result = await self._critique_evaluation(
                    risk_type=risk_type,
                    risk_evaluation=risk_evaluation,
                    agent_profile=agent_profile,
                    evaluator_name=evaluator_name,
                    assessment_id=assessment_id
                )
                
                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç CriticEvaluation
                critic_evaluation = CriticEvaluation(
                    risk_type=risk_type,
                    quality_score=critic_result["quality_score"],
                    is_acceptable=critic_result["is_acceptable"],
                    issues_found=critic_result.get("issues_found", []),
                    improvement_suggestions=critic_result.get("improvement_suggestions", []),
                    critic_reasoning=critic_result["critic_reasoning"]
                )
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫—Ä–∏—Ç–∏–∫–∏
                self.logger.log_critic_feedback(
                    assessment_id,
                    risk_type.value,
                    critic_evaluation.quality_score,
                    critic_evaluation.is_acceptable
                )
                
                end_time = datetime.now()
                execution_time = (end_time - start_time).total_seconds()
                
                return AgentTaskResult(
                    agent_name=self.name,
                    task_type="critic_analysis",
                    status=ProcessingStatus.COMPLETED,
                    result_data={
                        "critic_evaluation": critic_evaluation.dict(),
                        "raw_llm_response": critic_result,
                        "requires_retry": not critic_evaluation.is_acceptable
                    },
                    start_time=start_time,
                    end_time=end_time,
                    execution_time_seconds=execution_time
                )
                
        except Exception as e:
            end_time = datetime.now()
            execution_time = (end_time - start_time).total_seconds()
            
            return AgentTaskResult(
                agent_name=self.name,
                task_type="critic_analysis",
                status=ProcessingStatus.FAILED,
                error_message=str(e),
                start_time=start_time,
                end_time=end_time,
                execution_time_seconds=execution_time
            )
    
    async def _critique_evaluation(
        self,
        risk_type: RiskType,
        risk_evaluation: Dict[str, Any],
        agent_profile: Dict[str, Any],
        evaluator_name: str,
        assessment_id: str
    ) -> Dict[str, Any]:
        """–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞"""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥ RiskAnalysisLLMClient
        from ..utils.llm_client import RiskAnalysisLLMClient
        
        if not isinstance(self.llm_client, RiskAnalysisLLMClient):
            raise ValueError("–ö—Ä–∏—Ç–∏–∫ –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RiskAnalysisLLMClient")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞
        agent_data = self._format_agent_data_for_critique(agent_profile)
        
        # –í—ã–∑—ã–≤–∞–µ–º –º–µ—Ç–æ–¥ –∫—Ä–∏—Ç–∏–∫–∏
        critic_result = await self.llm_client.critique_evaluation(
            risk_type=risk_type.value,
            original_evaluation=risk_evaluation,
            agent_data=agent_data,
            quality_threshold=self.quality_threshold
        )
        
        return critic_result
    
    async def critique_multiple_evaluations(
        self,
        evaluation_results: Dict[str, Any],  # –¢–µ–ø–µ—Ä—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç Dict –≤–º–µ—Å—Ç–æ AgentTaskResult
        agent_profile: Dict[str, Any],
        assessment_id: str
    ) -> Dict[str, Dict[str, Any]]:
        """
        –ö—Ä–∏—Ç–∏–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ - –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
        
        Args:
            evaluation_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–æ–≤-–æ—Ü–µ–Ω—â–∏–∫–æ–≤ (–∏–∑ get_evaluation_results())
            agent_profile: –ü—Ä–æ—Ñ–∏–ª—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
            assessment_id: ID –æ—Ü–µ–Ω–∫–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ —Ç–∏–ø–∞–º —Ä–∏—Å–∫–æ–≤
        """
        critic_results = {}
        
        for risk_type, eval_result in evaluation_results.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ
            if (eval_result and 
                isinstance(eval_result, dict) and 
                eval_result.get("status") == "completed" and 
                eval_result.get("result_data")):
                
                risk_evaluation = eval_result["result_data"].get("risk_evaluation")
                
                if risk_evaluation:
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏
                    input_data = {
                        "risk_type": risk_type,
                        "risk_evaluation": risk_evaluation,
                        "agent_profile": agent_profile,
                        "evaluator_name": eval_result.get("agent_name", "Unknown")
                    }
                    
                    try:
                        # –í—ã–ø–æ–ª–Ω—è–µ–º –∫—Ä–∏—Ç–∏–∫—É
                        critic_result = await self.run(input_data, assessment_id)
                        critic_results[risk_type] = critic_result
                        
                    except Exception as e:
                        # –ï—Å–ª–∏ –∫—Ä–∏—Ç–∏–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, —Å–æ–∑–¥–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        self.logger.bind_context(assessment_id, self.name).error(
                            f"‚ùå –û—à–∏–±–∫–∞ –∫—Ä–∏—Ç–∏–∫–∏ {risk_type}: {e}"
                        )
                        
                        critic_results[risk_type] = self._create_default_critic_result(
                            risk_type, f"–û—à–∏–±–∫–∞ –∫—Ä–∏—Ç–∏–∫–∏: {str(e)}"
                        )
                else:
                    # –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏
                    critic_results[risk_type] = self._create_default_critic_result(
                        risk_type, "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏"
                    )
            else:
                # –ù–µ—É–¥–∞—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                critic_results[risk_type] = self._create_default_critic_result(
                    risk_type, "–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞ –Ω–µ –±—ã–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ"
                )
        
        return critic_results

    def _create_default_critic_result(self, risk_type: str, error_message: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫—Ä–∏—Ç–∏–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö"""
        from ..models.risk_models import AgentTaskResult, ProcessingStatus
        from datetime import datetime
        
        # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫—Ä–∏—Ç–∏–∫–∞
        default_critic_evaluation = {
            "quality_score": 5.0,  # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞
            "is_acceptable": True,  # –ü—Ä–∏–Ω–∏–º–∞–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å
            "issues_found": [error_message],
            "improvement_suggestions": ["–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –æ—Ü–µ–Ω–∫—É", "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞"],
            "critic_reasoning": f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {error_message}"
        }
        
        return AgentTaskResult(
            agent_name=self.name,
            task_type="critic_analysis",
            status=ProcessingStatus.COMPLETED,
            result_data={
                "critic_evaluation": default_critic_evaluation,
                "requires_retry": False  # –ù–µ —Ç—Ä–µ–±—É–µ–º –ø–æ–≤—Ç–æ—Ä–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –∫—Ä–∏—Ç–∏–∫–∞
            },
            start_time=datetime.now(),
            end_time=datetime.now(),
            execution_time_seconds=0.1
        ).dict()
    
    def _format_agent_data_for_critique(self, agent_profile: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        return f"""–ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú–´–ô –ò–ò-–ê–ì–ï–ù–¢:
–ù–∞–∑–≤–∞–Ω–∏–µ: {agent_profile.get('name', 'Unknown')}
–¢–∏–ø: {agent_profile.get('agent_type', 'unknown')}
–û–ø–∏—Å–∞–Ω–∏–µ: {agent_profile.get('description', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–ê–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å: {agent_profile.get('autonomy_level', 'unknown')}
–î–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º: {', '.join(agent_profile.get('data_access', []))}
–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: {agent_profile.get('target_audience', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
LLM –º–æ–¥–µ–ª—å: {agent_profile.get('llm_model', 'unknown')}

–û–ü–ï–†–ê–¶–ò–û–ù–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò:
–û–ø–µ—Ä–∞—Ü–∏–π –≤ —á–∞—Å: {agent_profile.get('operations_per_hour', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–î–æ—Ö–æ–¥ —Å –æ–ø–µ—Ä–∞—Ü–∏–∏: {agent_profile.get('revenue_per_operation', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')} —Ä—É–±
–í–Ω–µ—à–Ω–∏–µ API: {', '.join(agent_profile.get('external_apis', ['–ù–µ—Ç']))}

–°–ò–°–¢–ï–ú–ù–´–ï –ü–†–û–ú–ü–¢–´:
{chr(10).join(agent_profile.get('system_prompts', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{chr(10).join(agent_profile.get('guardrails', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}"""
    
    def analyze_quality_trends(
        self, 
        critic_results: Dict[RiskType, AgentTaskResult]
    ) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ü–µ–Ω–æ–∫
        
        Args:
            critic_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–≤–æ–¥–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –æ—Ü–µ–Ω–æ–∫
        """
        quality_scores = []
        acceptable_count = 0
        issues_summary = {}
        
        for risk_type, result in critic_results.items():
            if (result.status == ProcessingStatus.COMPLETED and 
                result.result_data and 
                "critic_evaluation" in result.result_data):
                
                critic_eval = result.result_data["critic_evaluation"]
                quality_scores.append(critic_eval["quality_score"])
                
                if critic_eval["is_acceptable"]:
                    acceptable_count += 1
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø—Ä–æ–±–ª–µ–º–∞–º
                for issue in critic_eval.get("issues_found", []):
                    if issue not in issues_summary:
                        issues_summary[issue] = 0
                    issues_summary[issue] += 1
        
        if not quality_scores:
            return {"error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}
        
        return {
            "average_quality": sum(quality_scores) / len(quality_scores),
            "min_quality": min(quality_scores),
            "max_quality": max(quality_scores),
            "acceptable_rate": acceptable_count / len(critic_results),
            "total_evaluations": len(critic_results),
            "common_issues": sorted(issues_summary.items(), key=lambda x: x[1], reverse=True)[:5],
            "quality_threshold": self.quality_threshold
        }
    
    def get_retry_recommendations(
        self, 
        critic_results: Dict[RiskType, AgentTaskResult]
    ) -> List[RiskType]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º –æ—Ü–µ–Ω–∫–∞–º
        
        Args:
            critic_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ —Ä–∏—Å–∫–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
        """
        retry_needed = []
        
        for risk_type, result in critic_results.items():
            if (result.status == ProcessingStatus.COMPLETED and 
                result.result_data and 
                "requires_retry" in result.result_data):
                
                if result.result_data["requires_retry"]:
                    retry_needed.append(risk_type)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (—Å–∞–º—ã–µ –Ω–∏–∑–∫–∏–µ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–≤—ã–º–∏)
        def get_quality_score(risk_type):
            result = critic_results.get(risk_type)
            if (result and result.result_data and 
                "critic_evaluation" in result.result_data):
                return result.result_data["critic_evaluation"]["quality_score"]
            return 10.0  # –í—ã—Å–æ–∫–∏–π –±–∞–ª–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        retry_needed.sort(key=get_quality_score)
        
        return retry_needed
    
    def generate_improvement_report(
        self, 
        critic_results: Dict[RiskType, AgentTaskResult]
    ) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
        
        Args:
            critic_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        report = {
            "assessment_summary": self.analyze_quality_trends(critic_results),
            "risk_type_analysis": {},
            "overall_recommendations": [],
            "priority_issues": []
        }
        
        all_suggestions = []
        priority_issues = []
        
        for risk_type, result in critic_results.items():
            if (result.status == ProcessingStatus.COMPLETED and 
                result.result_data and 
                "critic_evaluation" in result.result_data):
                
                critic_eval = result.result_data["critic_evaluation"]
                
                report["risk_type_analysis"][risk_type.value] = {
                    "quality_score": critic_eval["quality_score"],
                    "is_acceptable": critic_eval["is_acceptable"],
                    "main_issues": critic_eval.get("issues_found", []),
                    "suggestions": critic_eval.get("improvement_suggestions", [])
                }
                
                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                all_suggestions.extend(critic_eval.get("improvement_suggestions", []))
                
                # –í—ã–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã (–Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
                if critic_eval["quality_score"] < self.quality_threshold:
                    priority_issues.extend(critic_eval.get("issues_found", []))
        
        # –û–±–æ–±—â–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        suggestion_counts = {}
        for suggestion in all_suggestions:
            if suggestion not in suggestion_counts:
                suggestion_counts[suggestion] = 0
            suggestion_counts[suggestion] += 1
        
        # –¢–æ–ø —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (—É–ø–æ–º–∏–Ω–∞–µ–º—ã–µ —á–∞—â–µ –≤—Å–µ–≥–æ)
        report["overall_recommendations"] = [
            suggestion for suggestion, count in 
            sorted(suggestion_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        ]
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
        issue_counts = {}
        for issue in priority_issues:
            if issue not in issue_counts:
                issue_counts[issue] = 0
            issue_counts[issue] += 1
        
        report["priority_issues"] = [
            issue for issue, count in 
            sorted(issue_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        ]
        
        return report


# ===============================
# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LangGraph
# ===============================

def create_critic_node_function(critic_agent: CriticAgent):
    """
    –°–æ–∑–¥–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é —É–∑–ª–∞ –∫—Ä–∏—Ç–∏–∫–∞ –¥–ª—è LangGraph workflow
    
    Args:
        critic_agent: –≠–∫–∑–µ–º–ø–ª—è—Ä –∫—Ä–∏—Ç–∏–∫-–∞–≥–µ–Ω—Ç–∞
        
    Returns:
        –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ LangGraph
    """
    async def critic_node(state: Dict[str, Any]) -> Dict[str, Any]:
        """–£–∑–µ–ª –∫—Ä–∏—Ç–∏–∫–∞ –≤ LangGraph workflow"""
        
        assessment_id = state.get("assessment_id", "unknown")
        agent_profile = state.get("agent_profile", {})
        evaluation_results = state.get("evaluation_results", {})
        
        # –ö—Ä–∏—Ç–∏–∫—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
        critic_results = await critic_agent.critique_multiple_evaluations(
            evaluation_results=evaluation_results,
            agent_profile=agent_profile,
            assessment_id=assessment_id
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        updated_state = state.copy()
        updated_state["critic_results"] = critic_results
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω—ã –ª–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
        retry_needed = critic_agent.get_retry_recommendations(critic_results)
        updated_state["retry_needed"] = retry_needed
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        quality_report = critic_agent.generate_improvement_report(critic_results)
        updated_state["quality_report"] = quality_report
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ workflow
        if retry_needed:
            updated_state["current_step"] = "retry_evaluations"
        else:
            updated_state["current_step"] = "finalization"
        
        return updated_state
    
    return critic_node


def create_quality_check_router(quality_threshold: float = 7.0):
    """
    –°–æ–∑–¥–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    
    Args:
        quality_threshold: –ü–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
        
    Returns:
        –§—É–Ω–∫—Ü–∏—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è LangGraph
    """
    def quality_check_router(state: Dict[str, Any]) -> str:
        """–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫—Ä–∏—Ç–∏–∫–∞"""
        
        retry_needed = state.get("retry_needed", [])
        max_retries = state.get("max_retries", 3)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤
        retry_count = state.get("retry_count", {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–∏—Å–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—â–µ –º–æ–∂–Ω–æ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å
        retriable_risks = []
        for risk_type in retry_needed:
            current_retries = retry_count.get(risk_type.value, 0)
            if current_retries < max_retries:
                retriable_risks.append(risk_type)
        
        if retriable_risks:
            return "retry_evaluations"
        else:
            return "finalization"
    
    return quality_check_router


# ===============================
# –§–∞–±—Ä–∏–∫–∏
# ===============================

def create_critic_agent(
    llm_base_url: str = "http://127.0.0.1:1234",
    llm_model: str = "qwen3-4b",
    temperature: float = 0.1,
    quality_threshold: float = 7.0
) -> CriticAgent:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∏—Ç–∏–∫-–∞–≥–µ–Ω—Ç–∞
    
    Args:
        llm_base_url: URL LLM —Å–µ—Ä–≤–µ—Ä–∞
        llm_model: –ú–æ–¥–µ–ª—å LLM
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        quality_threshold: –ü–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è –æ—Ü–µ–Ω–æ–∫
        
    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∫—Ä–∏—Ç–∏–∫-–∞–≥–µ–Ω—Ç
    """
    from .base_agent import create_agent_config
    
    config = create_agent_config(
        name="critic_agent",
        description="–ê–≥–µ–Ω—Ç –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ü–µ–Ω–æ–∫ —Ä–∏—Å–∫–æ–≤",
        llm_base_url=llm_base_url,
        llm_model=llm_model,
        temperature=temperature,
        max_retries=2,  # –ú–µ–Ω—å—à–µ –ø–æ–≤—Ç–æ—Ä–æ–≤ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∞
        timeout_seconds=90,
        use_risk_analysis_client=True  # –ö—Ä–∏—Ç–∏–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
    )
    
    return CriticAgent(config, quality_threshold)


def create_critic_from_env() -> CriticAgent:
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∏—Ç–∏–∫-–∞–≥–µ–Ω—Ç–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    import os
    
    return create_critic_agent(
        llm_base_url=os.getenv("LLM_BASE_URL", "http://127.0.0.1:1234"),
        llm_model=os.getenv("LLM_MODEL", "qwen3-4b"),
        temperature=float(os.getenv("LLM_TEMPERATURE", "0.1")),
        quality_threshold=float(os.getenv("QUALITY_THRESHOLD", "7.0"))
    )


# ===============================
# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫—Ä–∏—Ç–∏–∫–æ–π
# ===============================

def extract_critic_evaluations_from_results(
    critic_results: Dict[RiskType, AgentTaskResult]
) -> Dict[RiskType, CriticEvaluation]:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ CriticEvaluation –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫—Ä–∏—Ç–∏–∫–∞
    
    Args:
        critic_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã –∫—Ä–∏—Ç–∏–∫-–∞–≥–µ–Ω—Ç–∞
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ü–µ–Ω–æ–∫
    """
    critic_evaluations = {}
    
    for risk_type, task_result in critic_results.items():
        if (task_result.status == ProcessingStatus.COMPLETED and 
            task_result.result_data and 
            "critic_evaluation" in task_result.result_data):
            
            eval_data = task_result.result_data["critic_evaluation"]
            critic_evaluation = CriticEvaluation(**eval_data)
            critic_evaluations[risk_type] = critic_evaluation
    
    return critic_evaluations


def should_retry_evaluation(
    critic_evaluation: CriticEvaluation,
    current_retry_count: int,
    max_retries: int
) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
    
    Args:
        critic_evaluation: –û—Ü–µ–Ω–∫–∞ –∫—Ä–∏—Ç–∏–∫–∞
        current_retry_count: –¢–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤
        max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤
        
    Returns:
        True –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    """
    return (not critic_evaluation.is_acceptable and 
            current_retry_count < max_retries)


def format_critic_summary(critic_results: Dict[RiskType, AgentTaskResult]) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–π —Å–≤–æ–¥–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫—Ä–∏—Ç–∏–∫–∞
    
    Args:
        critic_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        
    Returns:
        –¢–µ–∫—Å—Ç–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
    """
    total_evaluations = len(critic_results)
    acceptable_count = 0
    quality_scores = []
    
    for result in critic_results.values():
        if (result.status == ProcessingStatus.COMPLETED and 
            result.result_data and 
            "critic_evaluation" in result.result_data):
            
            critic_eval = result.result_data["critic_evaluation"]
            quality_scores.append(critic_eval["quality_score"])
            
            if critic_eval["is_acceptable"]:
                acceptable_count += 1
    
    if not quality_scores:
        return "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"
    
    avg_quality = sum(quality_scores) / len(quality_scores)
    acceptance_rate = acceptable_count / total_evaluations * 100
    
    return f"""üìä –°–í–û–î–ö–ê –ö–†–ò–¢–ò–ß–ï–°–ö–û–ì–û –ê–ù–ê–õ–ò–ó–ê:
‚Ä¢ –í—Å–µ–≥–æ –æ—Ü–µ–Ω–æ–∫ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {total_evaluations}
‚Ä¢ –ü—Ä–∏–Ω—è—Ç—ã –±–µ–∑ –∑–∞–º–µ—á–∞–Ω–∏–π: {acceptable_count} ({acceptance_rate:.1f}%)
‚Ä¢ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {avg_quality:.1f}/10
‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω –æ—Ü–µ–Ω–æ–∫: {min(quality_scores):.1f} - {max(quality_scores):.1f}
‚Ä¢ –¢—Ä–µ–±—É—é—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏: {total_evaluations - acceptable_count}"""


# –≠–∫—Å–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –∏ —Ñ—É–Ω–∫—Ü–∏–π
__all__ = [
    "CriticAgent",
    "create_critic_agent",
    "create_critic_from_env",
    "create_critic_node_function",
    "create_quality_check_router",
    "extract_critic_evaluations_from_results",
    "should_retry_evaluation",
    "format_critic_summary"
]