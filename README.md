# 🤖 Система оценки рисков ИИ-агентов

Мультиагентная система для автоматизированной оценки операционных рисков ИИ-агентов на основе методики ПАО Сбербанк.

![Python](https://img.shields.io/badge/python-3.12+-blue.svg)
![LangGraph](https://img.shields.io/badge/LangGraph-0.2.21+-green.svg)
![Status](https://img.shields.io/badge/status-ready-brightgreen.svg)

## 🎯 Возможности системы

### 📊 Комплексная оценка рисков
- **6 типов операционных рисков** по методике Сбербанка
- **Шкала оценки**: 1-25 баллов (вероятность × тяжесть)
- **Уровни риска**: Низкий (1-6), Средний (7-14), Высокий (15+)

### 🤖 Мультиагентная архитектура
- **Профайлер-агент** - сбор и анализ данных об агенте
- **6 агентов-оценщиков** - специализированная оценка каждого типа риска
- **Критик-агент** - контроль качества и повторные оценки
- **LangGraph workflow** - оркестрация всего процесса

### 📁 Анализ разнообразных источников
- **Кодовая база**: Python, JavaScript, Java
- **Документация**: Word (.docx), Excel (.xlsx), PDF
- **Конфигурации**: JSON, YAML, текстовые файлы
- **Промпты и инструкции** из любых источников

## 🏗️ Архитектура системы

```
┌─────────────────┐    ┌──────────────────────────────────────┐
│   CLI Interface │    │            LangGraph Workflow         │
└─────────┬───────┘    └─────────────┬────────────────────────┘
          │                          │
          ▼                          ▼
┌─────────────────┐    ┌──────────────────────────────────────┐
│ Input Files     │───▶│          Profiler Agent              │
│ • Code          │    └─────────────┬────────────────────────┘
│ • Docs          │                  │
│ • Configs       │                  ▼
└─────────────────┘    ┌──────────────────────────────────────┐
                       │       Parallel Risk Evaluation       │
                       │  ┌─────────┐ ┌─────────┐ ┌─────────┐│
                       │  │Ethical  │ │Security │ │Social   ││
                       │  └─────────┘ └─────────┘ └─────────┘│
                       │  ┌─────────┐ ┌─────────┐ ┌─────────┐│
                       │  │Stability│ │Autonomy │ │Regulatory││
                       │  └─────────┘ └─────────┘ └─────────┘│
                       └─────────────┬────────────────────────┘
                                     │
                                     ▼
                       ┌──────────────────────────────────────┐
                       │           Critic Agent               │
                       │        Quality Control &             │
                       │         Retry Logic                  │
                       └─────────────┬────────────────────────┘
                                     │
                                     ▼
                       ┌──────────────────────────────────────┐
                       │       Final Assessment &             │
                       │       Database Storage               │
                       └──────────────────────────────────────┘
```

## 🚀 Быстрый старт

### 1. Установка зависимостей

```bash
# Создание виртуального окружения
python -m venv ai_risk_env
source ai_risk_env/bin/activate  # Linux/Mac
# ai_risk_env\Scripts\activate   # Windows

# Установка зависимостей
pip install -r requirements.txt
```

### 2. Настройка LM Studio

```bash
# Запустите LM Studio
# Загрузите модель qwen3-8b
# Запустите сервер на localhost:1234
curl http://localhost:1234/v1/models  # Проверка
```

### 3. Запуск оценки

```bash
# Базовая оценка
python main.py assess /path/to/agent/files

# С дополнительными параметрами
python main.py assess /path/to/agent/ \
  --agent-name "MyAgent" \
  --output results.json \
  --quality-threshold 8.0

# Демонстрация на тестовых данных
python main.py demo
```

## 📖 Детальное использование

### Команды CLI

#### Оценка рисков агента
```bash
python main.py assess <files/folders> [OPTIONS]

OPTIONS:
  --agent-name, -n         Имя агента
  --output, -o            Файл для сохранения результата (JSON)
  --quality-threshold, -q  Порог качества критика (0-10)
  --max-retries, -r       Максимум повторов
  --model, -m             LLM модель
```

#### Просмотр результатов
```bash
# Показать конкретную оценку
python main.py show <assessment_id>

# Список всех оценок
python main.py list-assessments --limit 20

# Статус системы
python main.py status --check-llm --check-db
```

### Типы анализируемых файлов

| Тип | Расширения | Извлекаемая информация |
|-----|------------|------------------------|
| **Код** | `.py`, `.js`, `.java` | Функции, классы, импорты, промпты в коде |
| **Документы** | `.docx`, `.xlsx`, `.pdf` | Описания, техспеки, инструкции |
| **Конфигурации** | `.json`, `.yaml`, `.env` | Настройки, промпты, ограничения |
| **Тексты** | `.txt`, `.md` | Промпты, guardrails, описания |

### Пример структуры входных данных

```
my_agent/
├── agent_code.py           # Основной код агента
├── config.json            # Конфигурация  
├── documentation.docx     # Техническая документация
├── prompts.txt           # Системные промпты
└── guardrails.md         # Ограничения безопасности
```

## 📊 Типы рисков и критерии оценки

### 1. Этические и дискриминационные риски
- Обработка персональных данных
- Предвзятость в решениях
- Дискриминация групп пользователей

### 2. Риски ошибок и нестабильности LLM
- Халлюцинации модели
- Техническая нестабильность
- Качество ответов

### 3. Риски безопасности данных и систем
- Утечки данных
- Кибербезопасность
- Prompt injection

### 4. Риски автономности и управления
- Уровень самостоятельности
- Контроль решений
- Границы полномочий

### 5. Регуляторные и юридические риски
- Соответствие 152-ФЗ
- Требования ЦБ РФ
- Банковское законодательство

### 6. Социальные и манипулятивные риски
- Влияние на пользователей
- Дезинформация
- Социальные манипуляции

## 🔧 Конфигурация

### Переменные окружения (.env)
```bash
# LLM Configuration
LLM_BASE_URL=http://127.0.0.1:1234
LLM_MODEL=qwen3-8b
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4096

# Database
DATABASE_URL=sqlite:///./ai_risk_assessment.db

# Quality Control  
QUALITY_THRESHOLD=7.0
MAX_RETRY_COUNT=3
MAX_CONCURRENT_EVALUATIONS=6

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/ai_risk_assessment.log
```

### Настройка LLM модели
```python
# Для продакшена - замените на Qwen3-32B-AWQ
LLM_BASE_URL=https://your-llm-endpoint.com
LLM_MODEL=qwen3-32b-awq
```

## 📈 Пример результата оценки

```json
{
  "agent_name": "BankingAssistant",
  "overall_risk_level": "medium", 
  "overall_risk_score": 12,
  "risk_evaluations": {
    "ethical": {"score": 8, "level": "medium"},
    "stability": {"score": 5, "level": "low"},
    "security": {"score": 12, "level": "medium"},
    "autonomy": {"score": 6, "level": "low"},
    "regulatory": {"score": 9, "level": "medium"},
    "social": {"score": 4, "level": "low"}
  },
  "priority_recommendations": [
    "Внедрить мониторинг этических рисков",
    "Усилить механизмы информационной безопасности",
    "Добавить контроль над автономными решениями"
  ],
  "processing_time": 45.2,
  "quality_checks_passed": true
}
```

## 🧪 Тестирование

### Запуск всех тестов
```bash
# Полное тестирование системы
python test_complete_workflow.py

# Тесты отдельных компонентов
python test_stage1.py  # Базовая инфраструктура
python test_stage2.py  # Инструменты анализа  
python test_all_agents.py  # Агенты
```

### Быстрая проверка
```bash
# Демонстрация на тестовых данных
python main.py demo

# Проверка статуса
python main.py status --check-llm --check-db
```

## 📚 Структура проекта

```
AI_Risk_Assessment/
├── src/
│   ├── agents/              # Агенты системы
│   │   ├── base_agent.py    # Базовый класс
│   │   ├── profiler_agent.py # Профайлер
│   │   ├── evaluator_agents.py # 6 оценщиков
│   │   └── critic_agent.py   # Критик
│   ├── tools/               # Инструменты анализа
│   │   ├── document_parser.py
│   │   ├── code_analyzer.py
│   │   └── prompt_analyzer.py
│   ├── workflow/            # LangGraph workflow
│   │   └── graph_builder.py
│   ├── models/              # Модели данных
│   │   ├── risk_models.py
│   │   └── database.py
│   └── utils/               # Утилиты
│       ├── llm_client.py
│       └── logger.py
├── config/
│   └── prompts/             # Промпты агентов
├── tests/                   # Тесты
├── logs/                    # Логи
├── main.py                  # CLI интерфейс
├── requirements.txt         # Зависимости
└── .env                     # Конфигурация
```

## 🔍 Мониторинг и логирование

### Просмотр логов
```bash
# Общие логи
tail -f logs/ai_risk_assessment.log

# Логи конкретной оценки  
grep "assessment_12345" logs/ai_risk_assessment.log
```

### Метрики производительности
- Время профилирования: ~5-15 секунд
- Время оценки одного риска: ~10-30 секунд  
- Общее время оценки: ~60-180 секунд
- Поддерживаемый объем файлов: до 100 файлов

## ⚠️ Ограничения и рекомендации

### Текущие ограничения
- Работает только с текстовыми форматами
- Требует запущенный LM Studio
- Анализ ограничен размером контекста LLM
- Не анализирует двоичные файлы

### Рекомендации по использованию
- Предоставляйте полную документацию агента
- Включайте все промпты и конфигурации
- Структурируйте код для лучшего анализа
- Регулярно обновляйте базу рисков

## 🛠️ Разработка и расширение

### Добавление нового типа риска
1. Расширьте `RiskType` enum в `risk_models.py`
2. Создайте новый агент-оценщик в `evaluator_agents.py`
3. Обновите workflow в `graph_builder.py`
4. Добавьте промпты в `config/prompts/`

### Интеграция новых LLM
1. Расширьте `LLMClient` в `llm_client.py`
2. Обновите конфигурацию в `.env`
3. Протестируйте совместимость

## 🤝 Вклад в проект

1. Fork репозитория
2. Создайте feature branch
3. Внесите изменения
4. Добавьте тесты
5. Создайте Pull Request

## 📄 Лицензия

MIT License - см. файл LICENSE

## 🆘 Поддержка

### Частые проблемы

**LM Studio недоступен**
```bash
# Проверьте запуск
curl http://localhost:1234/v1/models

# Перезапустите LM Studio
# Убедитесь что модель qwen3-8b загружена
# Проверьте порт 1234
```

**Ошибки парсинга документов**
```bash
# Проверьте кодировку файлов (UTF-8)
# Убедитесь что файлы не повреждены
# Проверьте поддерживаемые форматы
```

**Низкое качество оценок**
```bash
# Увеличьте quality_threshold
python main.py assess --quality-threshold 8.0

# Предоставьте больше документации
# Структурируйте промпты четче
```

### Получение помощи
- 📧 Email: support@example.com
- 🐛 Issues: GitHub Issues
- 📖 Wiki: GitHub Wiki
- 💬 Discussions: GitHub Discussions

---

## 🎉 Заключение

Система оценки рисков ИИ-агентов представляет собой комплексное решение для автоматизированного анализа операционных рисков. Используя современные технологии мультиагентных систем и LangGraph, она обеспечивает:

✅ **Полную автоматизацию** процесса оценки рисков
✅ **Высокое качество** анализа благодаря критик-агенту  
✅ **Масштабируемость** для различных типов ИИ-агентов
✅ **Прозрачность** результатов с детальными обоснованиями
✅ **Соответствие** банковским методикам оценки рисков

Система готова к промышленному использованию и может быть легко адаптирована под специфические требования организации.

**Версия системы**: 1.0.0  
**Дата релиза**: Декабрь 2024  
**Статус**: Production Ready ✅